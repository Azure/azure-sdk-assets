# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import pytest
import uuid
from datetime import datetime
from typing import Tuple, Union, Dict, Any, Optional
from devtools_testutils.aio import recorded_by_proxy_async
from testpreparer import ContentUnderstandingPreparer
from testpreparer_async import ContentUnderstandingClientTestBaseAsync
from azure.ai.contentunderstanding.models import ContentAnalyzer, ContentAnalyzerConfig, FieldSchema, FieldDefinition
from azure.ai.contentunderstanding.models import GenerationMethod, FieldType, AnalysisMode, ProcessingLocation


def generate_analyzer_id() -> str:
    """Generate a unique analyzer ID with current date, time, and GUID."""
    now = datetime.now()
    date_str = now.strftime("%Y%m%d")
    time_str = now.strftime("%H%M%S")
    guid = str(uuid.uuid4()).replace("-", "")[:8]
    return f"python-sdk-test-analyzer-{date_str}-{time_str}-{guid}"


def extract_operation_id_from_poller(poller) -> str:
    """Extract operation ID from an AsyncLROPoller.
    
    The AsyncLROPoller stores the initial response in `_initial_response`, which contains
    the Operation-Location header. This is the standard way to get operation IDs in Azure SDKs.
    
    Args:
        poller: The AsyncLROPoller instance
        
    Returns:
        str: The operation ID extracted from the poller
        
    Raises:
        ValueError: If no operation ID can be extracted from the poller
    """
    # Extract from Operation-Location header (standard approach)
    initial_response = poller.polling_method()._initial_response
    operation_location = initial_response.http_response.headers.get("Operation-Location")
    
    if operation_location:
        # Extract operation ID from URL: https://endpoint/.../operations/{operation_id}?api-version=...
        operation_id = operation_location.split("/operations/")[1].split("?")[0]
        return operation_id
    
    raise ValueError("Could not extract operation ID from poller")


async def analyzer_in_list(client, analyzer_id: str) -> bool:
    """Check if an analyzer with the given ID exists in the list of analyzers.
    
    Args:
        client: The ContentUnderstandingClient instance
        analyzer_id: The analyzer ID to search for
        
    Returns:
        bool: True if the analyzer is found, False otherwise
    """
    response = client.content_analyzers.list()
    async for r in response:
        if hasattr(r, 'analyzer_id') and r.analyzer_id == analyzer_id:
            return True
    return False


def new_simple_content_analyzer_object(analyzer_id: str, description: Optional[str] = None, tags: Optional[Dict[str, str]] = None) -> ContentAnalyzer:
    """Create a simple ContentAnalyzer object with default configuration.
    
    Args:
        analyzer_id: The analyzer ID
        description: Optional description for the analyzer
        tags: Optional tags for the analyzer
        
    Returns:
        ContentAnalyzer: A configured ContentAnalyzer object
    """
    if description is None:
        description = f"test analyzer: {analyzer_id}"
    if tags is None:
        tags = {"test_type": "simple"}
        
    return ContentAnalyzer(
        base_analyzer_id="prebuilt-documentAnalyzer",
        config=ContentAnalyzerConfig(
            enable_formula=True,
            enable_layout=True,
            enable_ocr=True,
            estimate_field_source_and_confidence=True,
            return_details=True,
        ),
        description=description,
        field_schema=FieldSchema(
            fields={
                "total_amount": FieldDefinition(
                    description="Total amount of this table",
                    method=GenerationMethod.EXTRACT,
                    type=FieldType.NUMBER,
                )
            },
            description="schema description here",
            name="schema name here",
        ),
        mode=AnalysisMode.STANDARD,
        processing_location=ProcessingLocation.GLOBAL,
        tags=tags,
    )


def assert_poller_properties(poller, poller_name: str = "Poller"):
    """Assert common poller properties for any AsyncLROPoller.
    
    Args:
        poller: The AsyncLROPoller instance to validate
        poller_name: Optional name for the poller in log messages
        
    Raises:
        AssertionError: If any poller property assertion fails
    """
    print(f"{poller_name}:\n{poller}")
    assert poller is not None, f"{poller_name} should not be None"
    assert poller.status() is not None, f"{poller_name} status should not be None"
    assert poller.status() is not "", f"{poller_name} status should not be empty"
    assert poller.continuation_token() is not None, f"{poller_name} continuation_token should not be None"
    print(f"{poller_name} properties verified successfully")


def assert_simple_content_analyzer_result(analysis_result, result_name: str = "Analysis result"):
    """Assert simple content analyzer result properties and field extraction.
    
    Args:
        analysis_result: The analysis result object to validate
        result_name: Optional name for the result in log messages
        
    Raises:
        AssertionError: If any analysis result property assertion fails
    """
    print(f"Validating {result_name} properties")
    assert analysis_result is not None, f"{result_name} should not be None"
    assert analysis_result.__class__.__name__ == "AnalyzeResult", f"{result_name} should be AnalyzeResult, got {analysis_result.__class__.__name__}"
    assert analysis_result.contents is not None, f"{result_name} should have contents"
    assert len(analysis_result.contents) > 0, f"{result_name} should have at least one content"
    
    print(f"{result_name} properties verified successfully")

    # Verify fields node exists in the first result of contents
    
    first_content = analysis_result.contents[0]
    assert hasattr(first_content, 'fields'), "First content should have fields"
    print(f"Verified fields node exists in first result")

    # Verify total_amount field exists and equals 110
    fields = first_content.fields
    
    # Fields is expected to be a dictionary
    assert isinstance(fields, dict), f"Fields should be a dictionary, got {type(fields)}"
    assert 'total_amount' in fields, f"Fields should contain total_amount. Available fields: {list(fields.keys())}"
    
    total_amount_field = fields['total_amount']
    assert total_amount_field is not None, "total_amount field should not be None"
    assert total_amount_field.__class__.__name__ == "NumberField", f"total_amount field should be of type Field, got {total_amount_field.__class__.__name__}"

    total_amount_value = total_amount_field.value_number
    
    print(f"Total amount field value: {total_amount_value}")
    assert total_amount_value == 110, f"Expected total_amount to be 110, but got {total_amount_value}"
    print(f"Total amount field validation successful")


def save_analysis_result_to_file(analysis_result, test_name: str, identifier: Optional[str] = None, output_dir: str = "test_output") -> str:
    """Save analysis result to output file using pytest naming convention.
    
    Args:
        analysis_result: The analysis result object to save
        test_name: Name of the test case (e.g., function name)
        identifier: Optional unique identifier for the result (e.g., analyzer_id)
        output_dir: Directory to save the output file (default: "test_output")
        
    Returns:
        str: Path to the saved output file
        
    Raises:
        OSError: If there are issues creating directory or writing file
    """
    import json
    import os
    from datetime import datetime
    
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate output filename with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Build filename with test name and optional identifier
    if identifier:
        output_filename = f"{output_dir}/{test_name}_{identifier}_{timestamp}.json"
    else:
        output_filename = f"{output_dir}/{test_name}_{timestamp}.json"
    
    # Save the analysis result
    with open(output_filename, "w") as output_file:
        json.dump(analysis_result.as_dict(), output_file, indent=2)
    
    print(f"Analysis result saved to: {output_filename}")
    return output_filename


async def create_analyzer_and_assert(
    client, 
    analyzer_id: str, 
    resource: Union[ContentAnalyzer, Dict[str, Any]]
) -> Tuple[Any, str]:
    """Create an analyzer and perform basic assertions.
    
    Args:
        client: The ContentUnderstandingClient instance
        analyzer_id: The analyzer ID to create
        resource: The analyzer resource (ContentAnalyzer object or dict)
        
    Returns:
        Tuple[Any, str]: A tuple containing (poller, operation_id)
        
    Raises:
        AssertionError: If the creation fails or assertions fail
    """
    print(f"Creating analyzer {analyzer_id}")
    
    # Start the analyzer creation operation
    poller = await client.content_analyzers.begin_create_or_replace(
        analyzer_id=analyzer_id,
        resource=resource,
    )

    # Extract operation_id from the poller using the helper function
    operation_id = extract_operation_id_from_poller(poller)
    print(f"Extracted operation_id: {operation_id}")

    # Check operation status while it's running
    print(f"Checking operation status for operation_id: {operation_id}")
    status_response = await client.content_analyzers.get_operation_status(
        analyzer_id=analyzer_id,
        operation_id=operation_id,
    )

    # Verify the operation status response
    assert status_response is not None
    print(f"Operation status: {status_response}")
    
    # Check that the operation status has expected fields
    assert hasattr(status_response, 'status') or hasattr(status_response, 'operation_status')
    assert hasattr(status_response, 'id')
    assert status_response.id == operation_id
    
    # Wait for the operation to complete
    print(f"Waiting for analyzer {analyzer_id} to be created")
    response = await poller.result()
    assert response is not None
    assert poller.status() == "Succeeded"
    assert poller.done()
    print(f"Analyzer {analyzer_id} is created successfully")
    
    # Additional poller assertions
    assert poller is not None
    assert poller.status() is not None
    assert poller.status() is not ""
    assert poller.continuation_token() is not None
    
    # Verify the analyzer is in the list
    assert await analyzer_in_list(client, analyzer_id), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
    print(f"Verified analyzer {analyzer_id} is in the list")
    
    return poller, operation_id

class TestContentUnderstandingContentAnalyzersOperationsAsync(ContentUnderstandingClientTestBaseAsync):
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get_operation_status(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Create analyzer and extract operation ID
        - Check operation status during creation
        - Wait for operation completion
        - Check final operation status after completion
        - Clean up created analyzer
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer for operation status: {analyzer_id}",
            tags={"test_type": "operation_status"}
        )

        try:
            # Create analyzer using the refactored function
            poller, operation_id = await create_analyzer_and_assert(client, analyzer_id, content_analyzer)
            created_analyzer = True

            # Check final operation status after completion
            final_status_response = await client.content_analyzers.get_operation_status(
                analyzer_id=analyzer_id,
                operation_id=operation_id,
            )
            
            assert final_status_response is not None
            print(f"Final operation status: {final_status_response}")

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_create_with_content_analyzer(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Create analyzer using ContentAnalyzer object
        - Verify analyzer creation and poller properties
        - Clean up created analyzer
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer: {analyzer_id}",
            tags={"tag1_name": "tag1_value"}
        )

        try:
            # Create analyzer using the refactored function
            poller, operation_id = await create_analyzer_and_assert(client, analyzer_id, content_analyzer)
            created_analyzer = True

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_create_with_json(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Create analyzer using JSON dictionary
        - Verify analyzer creation and poller properties
        - Clean up created analyzer
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        try:
            # Create analyzer using the refactored function with JSON resource
            poller, operation_id = await create_analyzer_and_assert(
                client, 
                analyzer_id, 
                {
                    "analyzerId": analyzer_id,
                    "baseAnalyzerId": "prebuilt-documentAnalyzer",
                    "config": {
                        "disableContentFiltering": False,
                        "disableFaceBlurring": False,
                        "enableFace": False,
                        "enableFormula": True,
                        "enableLayout": True,
                        "enableOcr": True,
                        "estimateFieldSourceAndConfidence": True,
                        "returnDetails": True,
                    },
                    "description": f"test analyzer: {analyzer_id}",
                    "fieldSchema": {
                        "fields": {
                            "total_amount": {
                                "description": "Total amount of this table",
                                "method": "extract",
                                "type": "number",
                            }
                        },
                        "description": "schema description here",
                        "name": "schema name here",
                    },
                    "mode": "standard",
                    "processingLocation": "global",
                    "tags": {"tag1_name": "tag1_value"},
                }
            )
            created_analyzer = True

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_update(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Create initial analyzer
        - Get analyzer before update to verify initial state
        - Update analyzer with new description and tags
        - Get analyzer after update to verify changes persisted
        - Clean up created analyzer
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        # Create initial analyzer
        initial_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"Initial analyzer for update test: {analyzer_id}",
            tags={"initial_tag": "initial_value"}
        )

        try:
            # Create the initial analyzer using the refactored function
            poller, operation_id = await create_analyzer_and_assert(client, analyzer_id, initial_analyzer)
            created_analyzer = True

            # Get the analyzer before update to verify initial state
            print(f"Getting analyzer {analyzer_id} before update")
            analyzer_before_update = await client.content_analyzers.get(analyzer_id=analyzer_id)
            assert analyzer_before_update is not None
            assert analyzer_before_update.analyzer_id == analyzer_id
            assert analyzer_before_update.description == f"Initial analyzer for update test: {analyzer_id}"
            assert analyzer_before_update.tags == {"initial_tag": "initial_value"}
            print(f"Initial analyzer state verified - description: {analyzer_before_update.description}, tags: {analyzer_before_update.tags}")

            # Create updated analyzer with only allowed properties (description and tags)
            updated_analyzer = ContentAnalyzer(
                description=f"Updated analyzer for update test: {analyzer_id}",
                tags={"initial_tag": "initial_value", "tag1_field": "updated_value"},
            )

            print(f"Updating analyzer {analyzer_id} with new tag and description")
            
            # Update the analyzer
            response = await client.content_analyzers.update(
                analyzer_id=analyzer_id,
                resource=updated_analyzer,
            )

            # Verify the update response
            assert response is not None
            print(f"Update response: {response}")
            
            # Verify the updated analyzer has the new tag and updated description
            assert response.analyzer_id == analyzer_id
            assert "tag1_field" in response.tags
            assert response.tags["tag1_field"] == "updated_value"
            assert response.description == f"Updated analyzer for update test: {analyzer_id}"
            
            print(f"Successfully updated analyzer {analyzer_id} with new tag and description")

            # Get the analyzer after update to verify the changes persisted
            print(f"Getting analyzer {analyzer_id} after update")
            analyzer_after_update = await client.content_analyzers.get(analyzer_id=analyzer_id)
            assert analyzer_after_update is not None
            assert analyzer_after_update.analyzer_id == analyzer_id
            assert analyzer_after_update.description == f"Updated analyzer for update test: {analyzer_id}"
            assert analyzer_after_update.tags == {"initial_tag": "initial_value", "tag1_field": "updated_value"}
            print(f"Updated analyzer state verified - description: {analyzer_after_update.description}, tags: {analyzer_after_update.tags}")

            # Verify the updated analyzer is in the list
            assert await analyzer_in_list(client, analyzer_id), f"Updated analyzer with ID '{analyzer_id}' was not found in the list"

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Get existing prebuilt analyzer
        - Verify analyzer properties and status
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.get(
            analyzer_id="prebuilt-documentAnalyzer",
        )
        assert response is not None
        print(response)
        assert response.analyzer_id == "prebuilt-documentAnalyzer"
        assert len(response.description) > 0
        assert response.status == "ready"
        assert response.created_at is not None
        assert response.config is not None

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_delete(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Create analyzer for deletion test
        - Verify analyzer exists in list before deletion
        - Delete analyzer
        - Verify analyzer no longer exists in list after deletion
        - Clean up if deletion failed
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        # Create a simple analyzer for deletion test
        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer for deletion: {analyzer_id}",
            tags={"test_type": "deletion"}
        )

        try:
            # Create analyzer using the refactored function
            poller, operation_id = await create_analyzer_and_assert(client, analyzer_id, content_analyzer)
            created_analyzer = True

            # Verify the analyzer is in the list before deletion
            assert await analyzer_in_list(client, analyzer_id), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
            print(f"Verified analyzer {analyzer_id} is in the list before deletion")

            # Delete the analyzer
            print(f"Deleting analyzer {analyzer_id}")
            response = await client.content_analyzers.delete(analyzer_id=analyzer_id)
            
            # Verify the delete response
            assert response is None
            
            # Verify the analyzer is no longer in the list after deletion
            assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
            print(f"Verified analyzer {analyzer_id} is no longer in the list after deletion")

        finally:
            # Clean up if the analyzer was created but deletion failed
            if created_analyzer and await analyzer_in_list(client, analyzer_id):
                print(f"Cleaning up analyzer {analyzer_id} that was not properly deleted")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    assert not await analyzer_in_list(client, analyzer_id), f"Failed to delete analyzer {analyzer_id} during cleanup"
                    print(f"Analyzer {analyzer_id} is deleted successfully during cleanup")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id} during cleanup: {e}")
            elif not created_analyzer:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")


    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_list(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - List all available analyzers
        - Verify list response
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = client.content_analyzers.list()
        result = [r async for r in response]
        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_analyze(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Begin analysis operation with analyzer
        - Wait for analysis completion
        - Verify analysis results
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await (
            await client.content_analyzers.begin_analyze(
                analyzer_id="str",
                body={
                    "data": bytes("bytes", encoding="utf-8"),
                    "inputs": [{"url": "str", "data": bytes("bytes", encoding="utf-8"), "name": "str"}],
                    "url": "str",
                },
            )
        ).result()  # call '.result()' to poll until service return final result

        # please add some check logic here by yourself
        # ...

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_analyze_binary(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Create simple analyzer for binary analysis
        - Read sample invoice PDF file
        - Begin binary analysis operation with analyzer
        - Wait for analysis completion
        - Save analysis result to output file
        - Verify fields node exists in first result
        - Verify total_amount field exists and equals 110
        - Clean up created analyzer
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        # Create a simple analyzer for binary analysis
        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer for binary analysis: {analyzer_id}",
            tags={"test_type": "binary_analysis"}
        )

        try:
            # Create analyzer using the refactored function
            poller, operation_id = await create_analyzer_and_assert(client, analyzer_id, content_analyzer)
            created_analyzer = True

            # Read the sample invoice PDF file
            pdf_path = "test_data/sample_invoice.pdf"
            with open(pdf_path, "rb") as pdf_file:
                pdf_content = pdf_file.read()

            print(f"Starting binary analysis with analyzer {analyzer_id}")
            
            # Begin binary analysis operation
            analysis_poller = await client.content_analyzers.begin_analyze_binary(
                analyzer_id=analyzer_id,
                input=pdf_content,
                content_type="application/pdf",
            )
            assert_poller_properties(analysis_poller, "Analysis poller")

            # Wait for analysis completion
            print(f"Waiting for analysis completion")
            analysis_result = await analysis_poller.result()
            print(f"Analysis completed")
            
            output_filename = save_analysis_result_to_file(analysis_result, "test_content_analyzers_begin_analyze_binary", analyzer_id)

            # Now assert the field results
            assert_simple_content_analyzer_result(analysis_result, "Analysis result")

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get_result(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Get analysis result by operation ID
        - Verify result contents and structure
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.get_result(
            operation_id="str",
        )
        # Check response is not None
        assert response is not None
        # Check response.contents is not None
        assert response.contents is not None
        # Check response.contents is not empty
        assert len(response.contents) > 0
        # Check response.contents[0].markdown is not None
        assert response.contents[0].markdown is not None

        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get_result_file(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Get specific result file by operation ID and path
        - Verify file content
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.get_result_file(
            operation_id="str",
            path="str",
        )

        # please add some check logic here by yourself
        # ...
