{
  "Entries": [
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:44 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "89ae652e-3e40-4337-ae46-ff86ad7944ed"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "10987",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:45 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "b478dfc7-8c04-44a6-a3d6-4413d39cd0e1",
        "x-ms-client-request-id": "89ae652e-3e40-4337-ae46-ff86ad7944ed",
        "x-ms-request-id": "a476b088-4b02-4987-8764-4bc18d7e07e1"
      },
      "ResponseBody": {
        "from": 0,
        "total": 7,
        "sessions": [
          {
            "id": 8,
            "appId": "application_1687994816026_0007",
            "appInfo": {
              "driverLogUrl": "http://vm-55b11507:8042/node/containerlogs/container_1687994816026_0007_01_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0007/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": "false",
              "impulseErrorCode": null,
              "impulseTsg": null,
              "impulseClassification": null
            },
            "state": "success",
            "log": [
              "\t tracking URL: http://vm-e6349682:8088/proxy/application_1687994816026_0007/",
              "\t user: trusted-service-user",
              "23/06/29 00:10:11 INFO ShutdownHookManager: Shutdown hook called",
              "23/06/29 00:10:11 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-c2075d4a-4520-4063-aeae-59ffcd324de8",
              "23/06/29 00:10:11 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-144014b0-60d5-4525-893d-5a30f6f5f700",
              "23/06/29 00:10:11 INFO MetricsSystemImpl: Stopping azure-file-system metrics system...",
              "23/06/29 00:10:11 INFO MetricsSystemImpl: azure-file-system metrics system stopped.",
              "23/06/29 00:10:11 INFO MetricsSystemImpl: azure-file-system metrics system shutdown complete.",
              "\nstderr: ",
              "\nYARN Diagnostics: "
            ],
            "registeredSources": null
          },
          {
            "id": 7,
            "appId": "application_1687994816026_0006",
            "appInfo": {
              "driverLogUrl": "http://vm-55b11507:8042/node/containerlogs/container_1687994816026_0006_02_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0006/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": null,
              "impulseErrorCode": "Spark_User_UserApp_ArrayIndexOutOfBoundsException",
              "impulseTsg": "Please verify if the application is attempting to access a non-existent array index.\nRemember that arrays are 0-indexed, so a 3-element array will have indexes 0, 1, 2.\n",
              "impulseClassification": "User"
            },
            "state": "dead",
            "log": [
              "\nstderr: ",
              "\nYARN Diagnostics: ",
              "User class threw exception: java.lang.ArrayIndexOutOfBoundsException: 0",
              "\tat WordCount$.main(WordCount.scala:12)",
              "\tat WordCount.main(WordCount.scala)",
              "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
              "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
              "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
              "\tat java.lang.reflect.Method.invoke(Method.java:498)",
              "\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:739)"
            ],
            "registeredSources": null
          },
          {
            "id": 6,
            "appId": "application_1687994816026_0005",
            "appInfo": {
              "driverLogUrl": "http://vm-55b11507:8042/node/containerlogs/container_1687994816026_0005_02_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0005/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": null,
              "impulseErrorCode": "Spark_User_UserApp_ArrayIndexOutOfBoundsException",
              "impulseTsg": "Please verify if the application is attempting to access a non-existent array index.\nRemember that arrays are 0-indexed, so a 3-element array will have indexes 0, 1, 2.\n",
              "impulseClassification": "User"
            },
            "state": "dead",
            "log": [
              "\nstderr: ",
              "\nYARN Diagnostics: ",
              "User class threw exception: java.lang.ArrayIndexOutOfBoundsException: 0",
              "\tat WordCount$.main(WordCount.scala:12)",
              "\tat WordCount.main(WordCount.scala)",
              "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
              "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
              "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
              "\tat java.lang.reflect.Method.invoke(Method.java:498)",
              "\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:739)"
            ],
            "registeredSources": null
          },
          {
            "id": 5,
            "appId": "application_1687994816026_0004",
            "appInfo": {
              "driverLogUrl": "http://vm-e6349682:8042/node/containerlogs/container_1687994816026_0004_02_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0004/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": "false",
              "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
              "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
              "impulseClassification": "Ambiguous"
            },
            "state": "dead",
            "log": [
              "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
              "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
              "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
              "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
              "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ],
            "registeredSources": null
          },
          {
            "id": 4,
            "appId": "application_1687994816026_0003",
            "appInfo": {
              "driverLogUrl": "http://vm-10011230:8042/node/containerlogs/container_1687994816026_0003_02_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0003/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": "false",
              "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
              "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
              "impulseClassification": "Ambiguous"
            },
            "state": "dead",
            "log": [
              "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
              "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
              "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
              "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
              "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ],
            "registeredSources": null
          },
          {
            "id": 3,
            "appId": "application_1687994816026_0002",
            "appInfo": {
              "driverLogUrl": "http://vm-10011230:8042/node/containerlogs/container_1687994816026_0002_02_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0002/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": "false",
              "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
              "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
              "impulseClassification": "Ambiguous"
            },
            "state": "dead",
            "log": [
              "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
              "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
              "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
              "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
              "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ],
            "registeredSources": null
          },
          {
            "id": 2,
            "appId": "application_1687994816026_0001",
            "appInfo": {
              "driverLogUrl": "http://vm-10011230:8042/node/containerlogs/container_1687994816026_0001_02_000001/trusted-service-user",
              "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0001/",
              "isSessionTimedOut": null,
              "isStreamingQueryExists": "false",
              "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
              "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
              "impulseClassification": "Ambiguous"
            },
            "state": "dead",
            "log": [
              "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
              "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
              "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
              "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
              "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
              "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
              "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ],
            "registeredSources": null
          }
        ]
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/8",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "bba690bb-eec2-4ceb-b1dd-fe3ad5916690"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1159",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "758d5cb3-7762-4b6c-82dd-07d107079e34",
        "x-ms-client-request-id": "bba690bb-eec2-4ceb-b1dd-fe3ad5916690",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/29/2023 12:10:46 AM \u002B00:00",
        "x-ms-job-internal-id": "8",
        "x-ms-job-livysubmission-on": "6/29/2023 12:10:00 AM \u002B00:00",
        "x-ms-job-queued-on": "6/29/2023 12:10:00 AM \u002B00:00",
        "x-ms-job-result": "Succeeded",
        "x-ms-job-scheduled-on": "6/29/2023 12:10:00 AM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/29/2023 12:09:52 AM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "8b050f40-60b6-4af2-959a-469e5ee490c4"
      },
      "ResponseBody": {
        "id": 8,
        "appId": "application_1687994816026_0007",
        "appInfo": {
          "driverLogUrl": "http://vm-55b11507:8042/node/containerlogs/container_1687994816026_0007_01_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0007/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": "false",
          "impulseErrorCode": null,
          "impulseTsg": null,
          "impulseClassification": null
        },
        "state": "success",
        "log": [
          "\t tracking URL: http://vm-e6349682:8088/proxy/application_1687994816026_0007/",
          "\t user: trusted-service-user",
          "23/06/29 00:10:11 INFO ShutdownHookManager: Shutdown hook called",
          "23/06/29 00:10:11 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-c2075d4a-4520-4063-aeae-59ffcd324de8",
          "23/06/29 00:10:11 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-144014b0-60d5-4525-893d-5a30f6f5f700",
          "23/06/29 00:10:11 INFO MetricsSystemImpl: Stopping azure-file-system metrics system...",
          "23/06/29 00:10:11 INFO MetricsSystemImpl: azure-file-system metrics system stopped.",
          "23/06/29 00:10:11 INFO MetricsSystemImpl: azure-file-system metrics system shutdown complete.",
          "\nstderr: ",
          "\nYARN Diagnostics: "
        ],
        "registeredSources": null
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/7",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "fe8698ca-b3c2-4a1a-982f-e6a63a8cf8ba"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1238",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "387b9e84-f253-4f47-9ce9-82111a6309fe",
        "x-ms-client-request-id": "fe8698ca-b3c2-4a1a-982f-e6a63a8cf8ba",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/28/2023 11:59:53 PM \u002B00:00",
        "x-ms-job-internal-id": "7",
        "x-ms-job-livysubmission-on": "6/28/2023 11:59:23 PM \u002B00:00",
        "x-ms-job-queued-on": "6/28/2023 11:59:23 PM \u002B00:00",
        "x-ms-job-result": "Failed",
        "x-ms-job-scheduled-on": "6/28/2023 11:59:22 PM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/28/2023 11:59:15 PM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "3363b227-b989-4d7c-a04a-1f7af4119ba8"
      },
      "ResponseBody": {
        "id": 7,
        "appId": "application_1687994816026_0006",
        "appInfo": {
          "driverLogUrl": "http://vm-55b11507:8042/node/containerlogs/container_1687994816026_0006_02_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0006/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": null,
          "impulseErrorCode": "Spark_User_UserApp_ArrayIndexOutOfBoundsException",
          "impulseTsg": "Please verify if the application is attempting to access a non-existent array index.\nRemember that arrays are 0-indexed, so a 3-element array will have indexes 0, 1, 2.\n",
          "impulseClassification": "User"
        },
        "state": "dead",
        "log": [
          "\nstderr: ",
          "\nYARN Diagnostics: ",
          "User class threw exception: java.lang.ArrayIndexOutOfBoundsException: 0",
          "\tat WordCount$.main(WordCount.scala:12)",
          "\tat WordCount.main(WordCount.scala)",
          "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
          "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
          "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
          "\tat java.lang.reflect.Method.invoke(Method.java:498)",
          "\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:739)"
        ],
        "registeredSources": null
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/6",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "6f02d552-ce7e-4456-b989-c60b73ed363a"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1238",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "0a55bea0-6f78-4d10-bac2-3838845ca021",
        "x-ms-client-request-id": "6f02d552-ce7e-4456-b989-c60b73ed363a",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/28/2023 11:49:26 PM \u002B00:00",
        "x-ms-job-internal-id": "6",
        "x-ms-job-livysubmission-on": "6/28/2023 11:48:55 PM \u002B00:00",
        "x-ms-job-queued-on": "6/28/2023 11:48:55 PM \u002B00:00",
        "x-ms-job-result": "Failed",
        "x-ms-job-scheduled-on": "6/28/2023 11:48:55 PM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/28/2023 11:48:45 PM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "0dd7feff-5253-41bf-a78d-a26081abf32d"
      },
      "ResponseBody": {
        "id": 6,
        "appId": "application_1687994816026_0005",
        "appInfo": {
          "driverLogUrl": "http://vm-55b11507:8042/node/containerlogs/container_1687994816026_0005_02_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0005/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": null,
          "impulseErrorCode": "Spark_User_UserApp_ArrayIndexOutOfBoundsException",
          "impulseTsg": "Please verify if the application is attempting to access a non-existent array index.\nRemember that arrays are 0-indexed, so a 3-element array will have indexes 0, 1, 2.\n",
          "impulseClassification": "User"
        },
        "state": "dead",
        "log": [
          "\nstderr: ",
          "\nYARN Diagnostics: ",
          "User class threw exception: java.lang.ArrayIndexOutOfBoundsException: 0",
          "\tat WordCount$.main(WordCount.scala:12)",
          "\tat WordCount.main(WordCount.scala)",
          "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
          "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
          "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
          "\tat java.lang.reflect.Method.invoke(Method.java:498)",
          "\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:739)"
        ],
        "registeredSources": null
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/5",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "d64c77d2-cd8f-449d-842c-064df30d26dc"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1828",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "9a1199ff-5b28-4525-a3bc-89c7d12cf17f",
        "x-ms-client-request-id": "d64c77d2-cd8f-449d-842c-064df30d26dc",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/28/2023 11:41:25 PM \u002B00:00",
        "x-ms-job-internal-id": "5",
        "x-ms-job-livysubmission-on": "6/28/2023 11:40:09 PM \u002B00:00",
        "x-ms-job-queued-on": "6/28/2023 11:40:09 PM \u002B00:00",
        "x-ms-job-result": "Failed",
        "x-ms-job-scheduled-on": "6/28/2023 11:40:09 PM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/28/2023 11:40:00 PM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "9c1f2adc-a498-407d-88d5-ceb8b980832a"
      },
      "ResponseBody": {
        "id": 5,
        "appId": "application_1687994816026_0004",
        "appInfo": {
          "driverLogUrl": "http://vm-e6349682:8042/node/containerlogs/container_1687994816026_0004_02_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0004/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": "false",
          "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
          "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
          "impulseClassification": "Ambiguous"
        },
        "state": "dead",
        "log": [
          "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
          "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
          "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
          "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
          "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
          "\tat java.lang.Thread.run(Thread.java:750)"
        ],
        "registeredSources": null
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/4",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "fd7ab046-c7c1-40bc-a53a-9062df15b88d"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1828",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "754a7280-7353-48c8-8c05-39547c70e433",
        "x-ms-client-request-id": "fd7ab046-c7c1-40bc-a53a-9062df15b88d",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/28/2023 11:39:52 PM \u002B00:00",
        "x-ms-job-internal-id": "4",
        "x-ms-job-livysubmission-on": "6/28/2023 11:38:37 PM \u002B00:00",
        "x-ms-job-queued-on": "6/28/2023 11:38:36 PM \u002B00:00",
        "x-ms-job-result": "Failed",
        "x-ms-job-scheduled-on": "6/28/2023 11:38:36 PM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/28/2023 11:38:28 PM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "b67d6d2e-7d75-4fd7-b041-cd1d6faf0d40"
      },
      "ResponseBody": {
        "id": 4,
        "appId": "application_1687994816026_0003",
        "appInfo": {
          "driverLogUrl": "http://vm-10011230:8042/node/containerlogs/container_1687994816026_0003_02_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0003/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": "false",
          "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
          "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
          "impulseClassification": "Ambiguous"
        },
        "state": "dead",
        "log": [
          "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
          "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
          "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
          "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
          "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
          "\tat java.lang.Thread.run(Thread.java:750)"
        ],
        "registeredSources": null
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/3",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "67b7c2ff-932e-4e71-ab3a-d3f90baa537d"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1828",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "d1dc809c-af89-41b5-b77f-e998bb63692f",
        "x-ms-client-request-id": "67b7c2ff-932e-4e71-ab3a-d3f90baa537d",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/28/2023 11:32:15 PM \u002B00:00",
        "x-ms-job-internal-id": "3",
        "x-ms-job-livysubmission-on": "6/28/2023 11:31:00 PM \u002B00:00",
        "x-ms-job-queued-on": "6/28/2023 11:30:59 PM \u002B00:00",
        "x-ms-job-result": "Failed",
        "x-ms-job-scheduled-on": "6/28/2023 11:30:59 PM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/28/2023 11:30:51 PM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "851eb665-9c5c-4c1f-8c38-77da425b4ead"
      },
      "ResponseBody": {
        "id": 3,
        "appId": "application_1687994816026_0002",
        "appInfo": {
          "driverLogUrl": "http://vm-10011230:8042/node/containerlogs/container_1687994816026_0002_02_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0002/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": "false",
          "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
          "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
          "impulseClassification": "Ambiguous"
        },
        "state": "dead",
        "log": [
          "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
          "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
          "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
          "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
          "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
          "\tat java.lang.Thread.run(Thread.java:750)"
        ],
        "registeredSources": null
      }
    },
    {
      "RequestUri": "https://REDACTED/livyApi/versions/2019-11-01-preview/sparkPools/Spark1/batches/2",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "0",
        "Date": "Thu, 29 Jun 2023 00:19:47 GMT",
        "User-Agent": "azsdk-java-azure-analytics-synapse-spark/1.0.0-beta.6 (17.0.6; Windows 11; 10.0)",
        "x-ms-client-request-id": "d218cdf2-cc21-44c3-9a43-b8524194e603"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "Content-Length": "1828",
        "Content-Type": "application/json; charset=utf-8",
        "Date": "Thu, 29 Jun 2023 00:19:46 GMT",
        "Server": [
          "Kestrel",
          "Microsoft-HTTPAPI/2.0"
        ],
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
        "x-ms-activity-id": "4b6a7a0d-05b7-4488-bda1-fe7613a92703",
        "x-ms-client-request-id": "d218cdf2-cc21-44c3-9a43-b8524194e603",
        "x-ms-job-cluster": "https://hubservice2.westus2.azuresynapse.net:8001/api/v1.0/publish/137d069a-95d0-426f-8c28-aee36dec7bb5",
        "x-ms-job-clusterrequested-on": "1/1/0001 12:00:00 AM \u002B00:00",
        "x-ms-job-ended-on": "6/28/2023 11:28:27 PM \u002B00:00",
        "x-ms-job-internal-id": "2",
        "x-ms-job-livysubmission-on": "6/28/2023 11:26:57 PM \u002B00:00",
        "x-ms-job-queued-on": "6/28/2023 11:26:55 PM \u002B00:00",
        "x-ms-job-result": "Failed",
        "x-ms-job-scheduled-on": "6/28/2023 11:25:50 PM \u002B00:00",
        "x-ms-job-scheduler-state": "Ended",
        "x-ms-job-submitted-by-name": "shafang@microsoft.com",
        "x-ms-job-submitted-on": "6/28/2023 11:25:42 PM \u002B00:00",
        "x-ms-job-type": "SparkServiceBatch",
        "x-ms-request-id": "bce67478-7fd7-4c2b-8563-04322f0ba3f9"
      },
      "ResponseBody": {
        "id": 2,
        "appId": "application_1687994816026_0001",
        "appInfo": {
          "driverLogUrl": "http://vm-10011230:8042/node/containerlogs/container_1687994816026_0001_02_000001/trusted-service-user",
          "sparkUiUrl": "http://vm-e6349682:8088/proxy/application_1687994816026_0001/",
          "isSessionTimedOut": null,
          "isStreamingQueryExists": "false",
          "impulseErrorCode": "Spark_Ambiguous_UserApp_JobAborted",
          "impulseTsg": "Job was aborted due to user runtime error.\n\nThis can be be for many reasons, a common cause is:\n\n1. Ensure the files you are loading are of the format. If you\u0027re\n   loading data via read.parquet, ensure the format of the data\n   that is being read is indeed parquet. Consider gating wildcard\n   loads with the file type suffix you intend to load to avoid.\n   For example, instead of using a load string like\n\n   /path/to/my/parquet/files/*\n\n   Change this to:\n\n   /path/to/my/parquet/files/*.parquet\n\n   To avoid loading JSON files that might exist in the directory.\n",
          "impulseClassification": "Ambiguous"
        },
        "state": "dead",
        "log": [
          "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)",
          "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)",
          "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)",
          "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)",
          "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)",
          "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
          "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
          "\tat java.lang.Thread.run(Thread.java:750)"
        ],
        "registeredSources": null
      }
    }
  ],
  "Variables": {}
}
