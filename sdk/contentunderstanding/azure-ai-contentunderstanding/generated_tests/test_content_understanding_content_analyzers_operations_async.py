# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import pytest
import uuid
from datetime import datetime
from devtools_testutils.aio import recorded_by_proxy_async
from testpreparer import ContentUnderstandingPreparer
from testpreparer_async import ContentUnderstandingClientTestBaseAsync
from azure.ai.contentunderstanding.models import ContentAnalyzer, ContentAnalyzerConfig, FieldSchema, FieldDefinition
from azure.ai.contentunderstanding.models import GenerationMethod, FieldType, AnalysisMode, ProcessingLocation


def generate_analyzer_id() -> str:
    """Generate a unique analyzer ID with current date, time, and GUID."""
    now = datetime.now()
    date_str = now.strftime("%Y%m%d")
    time_str = now.strftime("%H%M%S")
    guid = str(uuid.uuid4()).replace("-", "")[:8]
    return f"python-sdk-test-analyzer-{date_str}-{time_str}-{guid}"


def extract_operation_id_from_poller(poller) -> str:
    """Extract operation ID from an AsyncLROPoller.
    
    The AsyncLROPoller stores the initial response in `_initial_response`, which contains
    the Operation-Location header. This is the standard way to get operation IDs in Azure SDKs.
    
    Args:
        poller: The AsyncLROPoller instance
        
    Returns:
        str: The operation ID extracted from the poller
        
    Raises:
        ValueError: If no operation ID can be extracted from the poller
    """
    # Extract from Operation-Location header (standard approach)
    initial_response = poller.polling_method()._initial_response
    operation_location = initial_response.http_response.headers.get("Operation-Location")
    
    if operation_location:
        # Extract operation ID from URL: https://endpoint/.../operations/{operation_id}?api-version=...
        operation_id = operation_location.split("/operations/")[1].split("?")[0]
        return operation_id
    
    raise ValueError("Could not extract operation ID from poller")


async def analyzer_in_list(client, analyzer_id: str) -> bool:
    """Check if an analyzer with the given ID exists in the list of analyzers.
    
    Args:
        client: The ContentUnderstandingClient instance
        analyzer_id: The analyzer ID to search for
        
    Returns:
        bool: True if the analyzer is found, False otherwise
    """
    response = client.content_analyzers.list()
    async for r in response:
        if hasattr(r, 'analyzer_id') and r.analyzer_id == analyzer_id:
            return True
    return False

class TestContentUnderstandingContentAnalyzersOperationsAsync(ContentUnderstandingClientTestBaseAsync):
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get_operation_status(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False
        operation_id = None

        content_analyzer = ContentAnalyzer(
            base_analyzer_id="prebuilt-documentAnalyzer",
            config=ContentAnalyzerConfig(
                enable_formula=True,
                enable_layout=True,
                enable_ocr=True,
                estimate_field_source_and_confidence=True,
                return_details=True,
            ),
            description=f"test analyzer for operation status: {analyzer_id}",
            field_schema=FieldSchema(
                fields={
                    "total_amount": FieldDefinition(
                        description="Total amount of this table",
                        method=GenerationMethod.EXTRACT,
                        type=FieldType.NUMBER,
                    )
                },
                description="schema for operation status test",
                name="operation_status_test_schema",
            ),
            mode=AnalysisMode.STANDARD,
            processing_location=ProcessingLocation.GLOBAL,
            tags={"test_type": "operation_status"},
        )

        try:
            print(f"Creating analyzer {analyzer_id} to test operation status")
            
            # Start the analyzer creation operation
            poller = await client.content_analyzers.begin_create_or_replace(
                analyzer_id=analyzer_id,
                resource=content_analyzer,
            )

            # Extract operation_id from the poller using the helper function
            operation_id = extract_operation_id_from_poller(poller)
            print(f"Extracted operation_id: {operation_id}")

            # Check operation status while it's running
            print(f"Checking operation status for operation_id: {operation_id}")
            status_response = await client.content_analyzers.get_operation_status(
                analyzer_id=analyzer_id,
                operation_id=operation_id,
            )

            # Verify the operation status response
            assert status_response is not None
            print(f"Operation status: {status_response}")
            
            # Check that the operation status has expected fields
            assert hasattr(status_response, 'status') or hasattr(status_response, 'operation_status')
            assert hasattr(status_response, 'id')
            assert status_response.id == operation_id
            
            # Wait for the operation to complete
            print(f"Waiting for analyzer {analyzer_id} to be created")
            response = await poller.result()
            assert response is not None
            assert poller.status() == "Succeeded"
            assert poller.done()
            print(f"Analyzer {analyzer_id} is created successfully")
            created_analyzer = True

            # Check final operation status after completion
            final_status_response = await client.content_analyzers.get_operation_status(
                analyzer_id=analyzer_id,
                operation_id=operation_id,
            )
            
            assert final_status_response is not None
            print(f"Final operation status: {final_status_response}")
            
            # Verify the analyzer is in the list
            assert await analyzer_in_list(client, analyzer_id), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
            print(f"Verified analyzer {analyzer_id} is in the list")

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_create_with_content_analyzer(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        content_analyzer = ContentAnalyzer(
            base_analyzer_id="prebuilt-documentAnalyzer",
            config=ContentAnalyzerConfig(
                disable_content_filtering=False,
                disable_face_blurring=False,
                enable_face=False,
                enable_formula=True,
                enable_layout=True,
                enable_ocr=True,
                estimate_field_source_and_confidence=True,
                return_details=True,
            ),
            description=f"test analyzer: {analyzer_id}",
            field_schema=FieldSchema(
                fields={
                    "total_amount": FieldDefinition(
                        description="Total amount of this table",
                        method=GenerationMethod.EXTRACT,
                        type=FieldType.NUMBER,
                    )
                },
                description="schema description here",
                name="schema name here",
            ),
            mode=AnalysisMode.STANDARD,
            processing_location=ProcessingLocation.GLOBAL,
            tags={"tag1_name": "tag1_value"},
        )

        try:
            print(f"Trying to create an analyzer with analyzer_id: {analyzer_id}")
            poller = await client.content_analyzers.begin_create_or_replace(
                analyzer_id=analyzer_id,
                resource=content_analyzer,
            )

            assert poller is not None
            assert poller.status() is not None
            assert poller.status() is not ""
            assert poller.continuation_token() is not None

            print(f"Waiting for analyzer {analyzer_id} to be created")
            response = await poller.result()
            assert response is not None
            assert poller.status() == "Succeeded"
            assert poller.done()
            print(f"Analyzer {analyzer_id} is created successfully")
            created_analyzer = True

            # Verify the analyzer is in the list
            assert await analyzer_in_list(client, analyzer_id), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
            print(f"Verified analyzer {analyzer_id} is in the list")

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_create_with_json(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id()
        created_analyzer = False

        try:
            print(f"Trying to create an analyzer with analyzer_id: {analyzer_id}")
            poller = await client.content_analyzers.begin_create_or_replace(
                analyzer_id=analyzer_id,
                resource={
                    "analyzerId": analyzer_id,
                    "baseAnalyzerId": "prebuilt-documentAnalyzer",
                    "config": {
                        "disableContentFiltering": False,
                        "disableFaceBlurring": False,
                        "enableFace": False,
                        "enableFormula": True,
                        "enableLayout": True,
                        "enableOcr": True,
                        "estimateFieldSourceAndConfidence": True,
                        "returnDetails": True,
                    },
                    "description": f"test analyzer: {analyzer_id}",
                    "fieldSchema": {
                        "fields": {
                            "total_amount": {
                                "description": "Total amount of this table",
                                "method": "extract",
                                "type": "number",
                            }
                        },
                        "description": "schema description here",
                        "name": "schema name here",
                    },
                    "mode": "standard",
                    "processingLocation": "global",
                    "tags": {"tag1_name": "tag1_value"},
                },
            )

            assert poller is not None
            assert poller.status() is not None
            assert poller.status() is not ""
            assert poller.continuation_token() is not None

            print(f"Waiting for analyzer {analyzer_id} to be created")
            response = await poller.result()
            assert response is not None
            assert poller.status() == "Succeeded"
            assert poller.done()
            print(f"Analyzer {analyzer_id} is created successfully")
            created_analyzer = True

            # Verify the analyzer is in the list
            assert await analyzer_in_list(client, analyzer_id), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
            print(f"Verified analyzer {analyzer_id} is in the list")

        finally:
            # Always clean up the created analyzer, even if the test fails
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                try:
                    await client.content_analyzers.delete(analyzer_id=analyzer_id)
                    # Verify deletion
                    assert not await analyzer_in_list(client, analyzer_id), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
                    print(f"Analyzer {analyzer_id} is deleted successfully")
                except Exception as e:
                    print(f"Warning: Failed to delete analyzer {analyzer_id}: {e}")
            else:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_update(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.update(
            analyzer_id="str",
            resource={
                "analyzerId": "str",
                "createdAt": "2020-02-20 00:00:00",
                "lastModifiedAt": "2020-02-20 00:00:00",
                "status": "str",
                "baseAnalyzerId": "str",
                "config": {
                    "disableContentFiltering": bool,
                    "disableFaceBlurring": bool,
                    "enableFace": bool,
                    "enableFormula": bool,
                    "enableLayout": bool,
                    "enableOcr": bool,
                    "estimateFieldSourceAndConfidence": bool,
                    "locales": ["str"],
                    "personDirectoryId": "str",
                    "returnDetails": bool,
                    "segmentationDefinition": "str",
                    "segmentationMode": "str",
                    "tableFormat": "str",
                },
                "description": "str",
                "fieldSchema": {
                    "fields": {
                        "str": {
                            "$ref": "str",
                            "description": "str",
                            "enum": ["str"],
                            "enumDescriptions": {"str": "str"},
                            "examples": ["str"],
                            "items": ...,
                            "method": "str",
                            "properties": {"str": ...},
                            "type": "str",
                        }
                    },
                    "definitions": {
                        "str": {
                            "$ref": "str",
                            "description": "str",
                            "enum": ["str"],
                            "enumDescriptions": {"str": "str"},
                            "examples": ["str"],
                            "items": ...,
                            "method": "str",
                            "properties": {"str": ...},
                            "type": "str",
                        }
                    },
                    "description": "str",
                    "name": "str",
                },
                "knowledgeSources": ["knowledge_source"],
                "mode": "str",
                "processingLocation": "str",
                "tags": {"str": "str"},
                "trainingData": "data_source",
            },
        )

        # please add some check logic here by yourself
        # ...

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.get(
            analyzer_id="prebuilt-documentAnalyzer",
        )
        assert response is not None
        print(response)
        assert response.analyzer_id == "prebuilt-documentAnalyzer"
        assert len(response.description) > 0
        assert response.status == "ready"
        assert response.created_at is not None
        assert response.config is not None
        assert response.processing_location is not None
        assert len(response.warnings) == 0

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_delete(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.delete(
            analyzer_id="str",
        )

        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_list(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = client.content_analyzers.list()
        result = [r async for r in response]
        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_analyze(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await (
            await client.content_analyzers.begin_analyze(
                analyzer_id="str",
                body={
                    "data": bytes("bytes", encoding="utf-8"),
                    "inputs": [{"url": "str", "data": bytes("bytes", encoding="utf-8"), "name": "str"}],
                    "url": "str",
                },
            )
        ).result()  # call '.result()' to poll until service return final result

        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_begin_analyze_binary(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await (
            await client.content_analyzers.begin_analyze_binary(
                analyzer_id="str",
                input=bytes("bytes", encoding="utf-8"),
                content_type="str",
            )
        ).result()  # call '.result()' to poll until service return final result

        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get_result(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.get_result(
            operation_id="str",
        )
        # Check response is not None
        assert response is not None
        # Check response.contents is not None
        assert response.contents is not None
        # Check response.contents is not empty
        assert len(response.contents) > 0
        # Check response.contents[0].markdown is not None
        assert response.contents[0].markdown is not None

        # please add some check logic here by yourself
        # ...

    @pytest.mark.skip(reason="Skipping all tests except test_content_analyzers_get")
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_content_analyzers_get_result_file(self, contentunderstanding_endpoint):
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        response = await client.content_analyzers.get_result_file(
            operation_id="str",
            path="str",
        )

        # please add some check logic here by yourself
        # ...
