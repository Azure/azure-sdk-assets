{
  "Entries": [
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "474",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "evaluation_metric": "fuzzy_match",
            "input": "{{item.query}}",
            "pass_threshold": 1.0,
            "reference": "{{item.query}}",
            "type": "text_similarity",
            "name": "Sanitized"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "3c31ccd2-455a-41a9-abda-9b8a1365bea2",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:52 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "423",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "43964663-0618-4910-976a-e9fcbec540c5"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "text_similarity",
            "input": "{{item.query}}",
            "reference": "{{item.query}}",
            "pass_threshold": 1.0,
            "evaluation_metric": "fuzzy_match"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746543052,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cc3ad081909c8e91131ae20ee6/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "6271d6be-b4d5-483a-9c18-803670da10d5",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:53 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "1163",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "4aa7da88-2c41-4129-b653-4628937280ff"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21cc3ad081909c8e91131ae20ee6",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543053,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "428",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "What is",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "a9f3e527-9e0a-4254-9b15-eae76392ef3a",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:54 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "758",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "15bdd7cb-c20d-4472-bfe0-b7f1e9d3595a"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "What is",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746543053,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cdf8a08190979ec5f6953f035c/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "823ad4aa-94f0-4f89-8793-0cbc282a0488",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:54 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "637",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "dd1174c7-d877-4843-9b2f-47721b09da4c"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21cdf8a08190979ec5f6953f035c",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543055,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "510",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": [
              {
                "content": "{{item.query}}",
                "role": "user"
              }
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "model": "gpt-4o",
            "name": "Sanitized",
            "passing_labels": [
              "just right"
            ],
            "type": "label_model"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "6cbc9f1e-1268-4835-bba1-6d1aa7404e8e",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:55 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "353",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "654a6434-abc1-4b69-a760-203b280f7f6a"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "label_model",
            "model": "gpt-4o",
            "input": [
              {
                "type": "message",
                "role": "user",
                "content": {
                  "type": "input_text",
                  "text": "{{item.query}}"
                }
              }
            ],
            "passing_labels": [
              "just right"
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "sampling_params": null
          }
        ],
        "name": "Sanitized",
        "created_at": 1746543055,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cf87088190a54b1c2d82de6901/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "b500bba6-5d6d-49d4-a25a-86d54194cf0d",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:55 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "115",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "6421e61e-2f13-4fe1-8d48-e00a763349b6"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21cf87088190a54b1c2d82de6901",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543055,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "426",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "hello",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "7440edff-a0cc-4938-b6e9-5b2ec9d9a0ae",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:55 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "38",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "62cd2d07-9155-4983-8a7a-bac0d6226d89"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "hello",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746543056,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21d01cc88190856b8466bc74f698/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "e8bd2741-8843-4f84-94ed-9b94d939d06e",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:50:55 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "106",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "1230a25b-c9fe-473f-8fde-2657c2f6e34a"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21d01cc88190856b8466bc74f698",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543056,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cc3ad081909c8e91131ae20ee6/runs/evalrun_681a21cd6ef08190ab3384f53355dfaa?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "202b42e0-22cc-4a1f-ab35-bdadcee57d65",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:01 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "48",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "f390d62d-8af6-41f0-8e9f-d1712d1e41c9"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21cc3ad081909c8e91131ae20ee6",
        "report_url": "https://platform.openai.com/evaluations/eval_681a21cc3ad081909c8e91131ae20ee6?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a21cd6ef08190ab3384f53355dfaa",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543053,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "similarity-c3bfe2c9-b093-41d1-bd29-c794886537df",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cc3ad081909c8e91131ae20ee6/runs/evalrun_681a21cd6ef08190ab3384f53355dfaa/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "c743594c-ff16-4eb7-9eb1-ad512771ec7e",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:01 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "58",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "0435784f-d182-42b1-9c2a-52af62b7458b"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543059,
            "run_id": "evalrun_681a21cd6ef08190ab3384f53355dfaa",
            "eval_id": "eval_681a21cc3ad081909c8e91131ae20ee6",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543059,
            "run_id": "evalrun_681a21cd6ef08190ab3384f53355dfaa",
            "eval_id": "eval_681a21cc3ad081909c8e91131ae20ee6",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543059,
            "run_id": "evalrun_681a21cd6ef08190ab3384f53355dfaa",
            "eval_id": "eval_681a21cc3ad081909c8e91131ae20ee6",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a21d3973c81909cfbf9a6e9594353",
        "last_id": "outputitem_681a21d3916c819098fb1b1d131afe36",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cdf8a08190979ec5f6953f035c/runs/evalrun_681a21cf126081909e2be10d777b544a?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "efafe010-ef46-4df7-a0a2-5069c73d3092",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:06 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "67",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "87a1171f-e06c-48cd-9c9d-477214e50746"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21cdf8a08190979ec5f6953f035c",
        "report_url": "https://platform.openai.com/evaluations/eval_681a21cdf8a08190979ec5f6953f035c?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a21cf126081909e2be10d777b544a",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543055,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 2,
          "passed": 1
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "starts with what is-aa3aa003-01da-4166-9127-c9bb5bd1f91a",
            "passed": 1,
            "failed": 2
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cdf8a08190979ec5f6953f035c/runs/evalrun_681a21cf126081909e2be10d777b544a/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "fd07c069-f31b-4781-b8af-fcc1ea10ea04",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:06 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "74",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "381b6d23-1da4-4867-9146-44ccc29f77d4"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543061,
            "run_id": "evalrun_681a21cf126081909e2be10d777b544a",
            "eval_id": "eval_681a21cdf8a08190979ec5f6953f035c",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543061,
            "run_id": "evalrun_681a21cf126081909e2be10d777b544a",
            "eval_id": "eval_681a21cdf8a08190979ec5f6953f035c",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543061,
            "run_id": "evalrun_681a21cf126081909e2be10d777b544a",
            "eval_id": "eval_681a21cdf8a08190979ec5f6953f035c",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a21d53f8081908f27c93f181cd4eb",
        "last_id": "outputitem_681a21d534288190b2b475b2d6b7f763",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cf87088190a54b1c2d82de6901/runs/evalrun_681a21cff05c8190bbf5f3d6246099cb?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "9d238979-dbbd-4ba7-8854-e6f376a2eb4b",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:10 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "40",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "e1665547-ed3e-4bbf-8bba-9fac20c1968a"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21cf87088190a54b1c2d82de6901",
        "report_url": "https://platform.openai.com/evaluations/eval_681a21cf87088190a54b1c2d82de6901?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a21cff05c8190bbf5f3d6246099cb",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543055,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 1,
          "passed": 2
        },
        "per_model_usage": [
          {
            "model_name": "gpt-4o-2024-11-20",
            "invocation_count": 3,
            "prompt_tokens": 397,
            "completion_tokens": 311,
            "total_tokens": 708,
            "cached_tokens": 0
          }
        ],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "label-3db96cc5-373d-4de4-8eb9-2e97fef3c1d1",
            "passed": 2,
            "failed": 1
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21cf87088190a54b1c2d82de6901/runs/evalrun_681a21cff05c8190bbf5f3d6246099cb/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "82844621-e8c4-426e-8f44-ca1292a4e55f",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:11 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "185",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "98bcd96c-46c2-4335-82f8-d0ed45088a2b"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543066,
            "run_id": "evalrun_681a21cff05c8190bbf5f3d6246099cb",
            "eval_id": "eval_681a21cf87088190a54b1c2d82de6901",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you create a run?"
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Interpret the user's query, considering potential meanings and contexts.\",\"conclusion\":\"The query pertains to creating a 'run,' which could mean various things depending on context.\"},{\"description\":\"Evaluate common meanings of 'run,' such as producing a batch of something, initializing a sequence, or facilitating a group activity.\",\"conclusion\":\"Prominent contexts include software execution, sports, manufacturing, or general activity initiation.\"},{\"description\":\"Request clarification or provide a general explanation tailored to common interpretations.\",\"conclusion\":\"Deliver an answer informed by possible intents, assuming the context isn't specified.\"}],\"result\":\"too short\"}"
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 255,
                    "completion_tokens": 125,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543065,
            "run_id": "evalrun_681a21cff05c8190bbf5f3d6246099cb",
            "eval_id": "eval_681a21cf87088190a54b1c2d82de6901",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you log a model?"
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Start by exploring the context of 'logging a model.' This may refer to recording and saving the configuration and parameters of a computational model.\",\"conclusion\":\"Logging a model involves saving its architecture, parameters, and training metadata in a structured format for future use.\"},{\"description\":\"Evaluate the process of logging a model, depending on the specific programming framework or context in which it is implemented.\",\"conclusion\":\"Different frameworks such as TensorFlow, PyTorch, and scikit-learn provide utilities for logging models.\"}],\"result\":\"just right\"}"
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 244,
                    "completion_tokens": 114,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543064,
            "run_id": "evalrun_681a21cff05c8190bbf5f3d6246099cb",
            "eval_id": "eval_681a21cf87088190a54b1c2d82de6901",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "What is the capital of France?`''\"</>{}{{]"
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Identify the question asked, specifically focusing on the request for information.\",\"conclusion\":\"The question pertains to identifying the capital city of a specific country, France.\"},{\"description\":\"Recall and provide the relevant factual information about the queried entity, France.\",\"conclusion\":\"The capital of France is Paris.\"}],\"result\":\"just right\"}"
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 209,
                    "completion_tokens": 72,
                    "prompt_tokens": 137,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a21da7f04819090ac4470ecf0f367",
        "last_id": "outputitem_681a21d8a49c8190920bc9d5ee8bef0a",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21d01cc88190856b8466bc74f698/runs/evalrun_681a21d0357081909840c9241be0b7bd?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "f6cea2c3-ddc4-498e-9acf-19d7f061d1ea",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:15 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "161",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "b53af3a9-078e-4afc-af44-539e4347491d"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a21d01cc88190856b8466bc74f698",
        "report_url": "https://platform.openai.com/evaluations/eval_681a21d01cc88190856b8466bc74f698?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a21d0357081909840c9241be0b7bd",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746543056,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 3,
          "passed": 0
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "contains hello-ea2e9713-c72b-4703-a52b-b73163e198f7",
            "passed": 0,
            "failed": 3
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a21d01cc88190856b8466bc74f698/runs/evalrun_681a21d0357081909840c9241be0b7bd/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "4e4e9b48-41f2-43f4-aba0-27cc53b54f97",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 14:51:15 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "65",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "51dc495c-ae1d-4930-9614-ad4acea73166"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543062,
            "run_id": "evalrun_681a21d0357081909840c9241be0b7bd",
            "eval_id": "eval_681a21d01cc88190856b8466bc74f698",
            "status": "fail",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543062,
            "run_id": "evalrun_681a21d0357081909840c9241be0b7bd",
            "eval_id": "eval_681a21d01cc88190856b8466bc74f698",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746543062,
            "run_id": "evalrun_681a21d0357081909840c9241be0b7bd",
            "eval_id": "eval_681a21d01cc88190856b8466bc74f698",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a21d64a848190ae48b4071af1d155",
        "last_id": "outputitem_681a21d644e88190abcd347d22d73178",
        "has_more": false
      }
    }
  ],
  "Variables": {}
}
