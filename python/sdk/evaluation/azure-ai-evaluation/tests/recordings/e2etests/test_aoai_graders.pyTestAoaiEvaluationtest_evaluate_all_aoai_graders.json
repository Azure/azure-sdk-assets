{
  "Entries": [
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "474",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "evaluation_metric": "fuzzy_match",
            "input": "{{item.query}}",
            "pass_threshold": 1.0,
            "reference": "{{item.query}}",
            "type": "text_similarity",
            "name": "Sanitized"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "a59e6655-1545-43ca-9ef0-ab5b54661291",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:52 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "137",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "61687607-e3d1-4f61-a0c2-063d42a96e66"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "text_similarity",
            "input": "{{item.query}}",
            "reference": "{{item.query}}",
            "pass_threshold": 1.0,
            "evaluation_metric": "fuzzy_match"
          }
        ],
        "name": "Sanitized",
        "created_at": 1745935492,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc843a7481908f8e5194f6dc02e1/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "4bb1ea09-0726-4b9c-8a55-aafc1e7be21a",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:52 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "287",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "9b084b40-9acc-4ab5-9710-4514af402096"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc843a7481908f8e5194f6dc02e1",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935492,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "428",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "What is",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "383da51e-aebb-441c-ba3e-b1404ffd7891",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:52 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "62",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "593c47a4-7658-4742-acfb-c3f43463cc84"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "What is",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1745935492,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc84d4b881909f9592469b1efc3d/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "1d272ce1-f755-4f74-bfc3-7cd77670b893",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:53 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "1033",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "0b98b9cb-a58d-4476-8863-c95ee40046e7"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc84d4b881909f9592469b1efc3d",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935493,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "510",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": [
              {
                "content": "{{item.query}}",
                "role": "user"
              }
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "model": "gpt-4o",
            "name": "Sanitized",
            "passing_labels": [
              "just right"
            ],
            "type": "label_model"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "b7cf1840-8cc0-4974-96de-bb458290f8a2",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:53 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "38",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "676c45d1-9e14-4024-94df-9ea47c5a11ab"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "label_model",
            "model": "gpt-4o",
            "input": [
              {
                "type": "message",
                "role": "user",
                "content": {
                  "type": "input_text",
                  "text": "{{item.query}}"
                }
              }
            ],
            "passing_labels": [
              "just right"
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "sampling_params": null
          }
        ],
        "name": "Sanitized",
        "created_at": 1745935494,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc8610bc819099d8436efe8da771/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "7887b7c7-ff31-42b8-90bf-31cbe8920432",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:54 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "536",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "598a885a-5959-44ef-a255-3347f2b4b2f8"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc8610bc819099d8436efe8da771",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935494,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "426",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "hello",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "ec94928e-d33b-4b5a-8b56-14b4128748a4",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:54 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "35",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "46992770-040e-488e-b4b4-bcd8270268ac"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "hello",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1745935494,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc86c884819096a3ef4d5aab5d6b/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "b77a02ac-7a90-4445-919f-2b170ed157ac",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:04:54 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "165",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "0ba8cd5f-cbae-4365-969f-6201dd621ab6"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc86c884819096a3ef4d5aab5d6b",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935494,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc843a7481908f8e5194f6dc02e1/runs/evalrun_6810dc84956c81908e8b6f69fa82935a?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "5d00420a-0b1b-4ee4-9d98-bb64aa18f6a3",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:00 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "146",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "4a579700-b2e6-46a6-8a9a-1b4add4857f3"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc843a7481908f8e5194f6dc02e1",
        "report_url": "https://platform.openai.com/evaluations/eval_6810dc843a7481908f8e5194f6dc02e1?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6810dc84956c81908e8b6f69fa82935a",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935492,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "similarity-3f50e3d2-531c-4d43-82dd-cf0410b41bc2",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc843a7481908f8e5194f6dc02e1/runs/evalrun_6810dc84956c81908e8b6f69fa82935a/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "671a60d1-d417-44e5-8d36-d03231252ea3",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:00 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "82",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "8c7ff1b2-e774-4ee9-8b4a-f08ce64e67e7"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935498,
            "run_id": "evalrun_6810dc84956c81908e8b6f69fa82935a",
            "eval_id": "eval_6810dc843a7481908f8e5194f6dc02e1",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935498,
            "run_id": "evalrun_6810dc84956c81908e8b6f69fa82935a",
            "eval_id": "eval_6810dc843a7481908f8e5194f6dc02e1",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935498,
            "run_id": "evalrun_6810dc84956c81908e8b6f69fa82935a",
            "eval_id": "eval_6810dc843a7481908f8e5194f6dc02e1",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6810dc8a4cf48190b1c81494ceb0e131",
        "last_id": "outputitem_6810dc8a2ccc81909eaf753512235453",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc84d4b881909f9592469b1efc3d/runs/evalrun_6810dc8587488190b75422ad7f478665?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "e9d19f2f-ef64-41c7-b75a-579b89d5a66f",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:05 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "32",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "09a94317-7437-4ac6-a3b3-c2454044177f"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc84d4b881909f9592469b1efc3d",
        "report_url": "https://platform.openai.com/evaluations/eval_6810dc84d4b881909f9592469b1efc3d?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6810dc8587488190b75422ad7f478665",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935493,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 2,
          "passed": 1
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "starts with what is-24229e91-9210-46d7-83a5-ce6c1c416dfb",
            "passed": 1,
            "failed": 2
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc84d4b881909f9592469b1efc3d/runs/evalrun_6810dc8587488190b75422ad7f478665/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "35744bd3-6173-4ccf-ad22-d7b3cfd76bc6",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:05 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "86",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "d69088f7-408b-4e0e-89f6-f201a6c94809"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935499,
            "run_id": "evalrun_6810dc8587488190b75422ad7f478665",
            "eval_id": "eval_6810dc84d4b881909f9592469b1efc3d",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935499,
            "run_id": "evalrun_6810dc8587488190b75422ad7f478665",
            "eval_id": "eval_6810dc84d4b881909f9592469b1efc3d",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935499,
            "run_id": "evalrun_6810dc8587488190b75422ad7f478665",
            "eval_id": "eval_6810dc84d4b881909f9592469b1efc3d",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6810dc8b90488190a60884836e2cf783",
        "last_id": "outputitem_6810dc8b87d88190a7fdcccad2821227",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc8610bc819099d8436efe8da771/runs/evalrun_6810dc863f8881909e9ad340183665a5?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "20b4ab55-b0c1-4221-988a-3574ace694f2",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:10 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "28",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "fc4a58cd-6197-4894-8709-7a32fb360108"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc8610bc819099d8436efe8da771",
        "report_url": "https://platform.openai.com/evaluations/eval_6810dc8610bc819099d8436efe8da771?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6810dc863f8881909e9ad340183665a5",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935494,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [
          {
            "model_name": "gpt-4o-2024-11-20",
            "invocation_count": 3,
            "prompt_tokens": 397,
            "completion_tokens": 308,
            "total_tokens": 705,
            "cached_tokens": 0
          }
        ],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "label-429ba44f-52a3-4eec-a065-d672637514f2",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc8610bc819099d8436efe8da771/runs/evalrun_6810dc863f8881909e9ad340183665a5/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "da066248-1c8b-4619-b0d2-1c44be5869b8",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:10 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "48",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "6e35d856-6534-4404-9a12-613dfc0fade0"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935502,
            "run_id": "evalrun_6810dc863f8881909e9ad340183665a5",
            "eval_id": "eval_6810dc8610bc819099d8436efe8da771",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you log a model?",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Consider how extensive the answer should be to meet the user's request accurately.\",\"conclusion\":\"Keep it concise and precise.\"},{\"description\":\"Review the query to determine if it assumes specifics or remains general.\",\"conclusion\":\"Assess that the question is broad and general in its request.\"},{\"description\":\"Provide a response detailing logging a model in machine learning.\",\"conclusion\":\"Compile the main strategies as examples.\"}],\"result\":\"just right\"}",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 222,
                    "completion_tokens": 92,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935502,
            "run_id": "evalrun_6810dc863f8881909e9ad340183665a5",
            "eval_id": "eval_6810dc8610bc819099d8436efe8da771",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "What is the capital of France?`''\"</>{}{{]",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Identify the main question from the input provided.\",\"conclusion\":\"The main question appears to be 'What is the capital of France?'\"},{\"description\":\"Answer the main question using known factual information.\",\"conclusion\":\"The capital of France is Paris.\"},{\"description\":\"Evaluate the length and completeness of the answer given.\",\"conclusion\":\"The response correctly and concisely answers the question in a complete manner.\"}],\"result\":\"just right\"}",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 231,
                    "completion_tokens": 94,
                    "prompt_tokens": 137,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935502,
            "run_id": "evalrun_6810dc863f8881909e9ad340183665a5",
            "eval_id": "eval_6810dc8610bc819099d8436efe8da771",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you create a run?",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Understanding that the response should address the query in detail.\",\"conclusion\":\"Identify what 'run' refers to in the context of the question.\"},{\"description\":\"Considering the various contexts where 'run' may apply, such as creating a 'career run', 'jogging practice', 'computer program execution', etc.\",\"conclusion\":\"Found that listing these as part of the response is suitable.\"},{\"description\":\"Structuring a concise response to effectively answer the question considering various interpretations.\",\"conclusion\":\"Drafted an answer with clarity and relevant examples.\"}],\"result\":\"just right\"}",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 252,
                    "completion_tokens": 122,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6810dc8eb47881908547465249a75171",
        "last_id": "outputitem_6810dc8e7494819091b397eebe625e9f",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc86c884819096a3ef4d5aab5d6b/runs/evalrun_6810dc86e11c8190be91c6a6e1d9304c?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "317c809b-f4ba-4083-b8dd-f2cadb127e73",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:14 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "30",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "13ce1c32-c6b9-4d56-a78f-a1f8abedb35f"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6810dc86c884819096a3ef4d5aab5d6b",
        "report_url": "https://platform.openai.com/evaluations/eval_6810dc86c884819096a3ef4d5aab5d6b?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6810dc86e11c8190be91c6a6e1d9304c",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1745935494,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 3,
          "passed": 0
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "contains hello-bb13dcfa-d3d4-44a5-a365-1b9bf352db84",
            "passed": 0,
            "failed": 3
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6810dc86c884819096a3ef4d5aab5d6b/runs/evalrun_6810dc86e11c8190be91c6a6e1d9304c/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "ee0be578-2beb-4ec7-80b3-5e1aa2ef0baa",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 29 Apr 2025 14:05:14 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "36",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "7f684c5c-d57d-4de4-9a3b-6d2613ba1f7c"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935500,
            "run_id": "evalrun_6810dc86e11c8190be91c6a6e1d9304c",
            "eval_id": "eval_6810dc86c884819096a3ef4d5aab5d6b",
            "status": "fail",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935500,
            "run_id": "evalrun_6810dc86e11c8190be91c6a6e1d9304c",
            "eval_id": "eval_6810dc86c884819096a3ef4d5aab5d6b",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1745935500,
            "run_id": "evalrun_6810dc86e11c8190be91c6a6e1d9304c",
            "eval_id": "eval_6810dc86c884819096a3ef4d5aab5d6b",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6810dc8cb39481908ee811f9b805f4d9",
        "last_id": "outputitem_6810dc8c9a7c8190bdc31aa0e0563132",
        "has_more": false
      }
    }
  ],
  "Variables": {}
}
