{
  "Entries": [
    {
      "RequestUri": "https://REDACTED/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-10-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "api-key": "REDACTED",
        "Content-Length": "278",
        "Content-Type": "application/json",
        "Date": "Tue, 26 Nov 2024 03:34:23 GMT",
        "User-Agent": "azsdk-java-azure-ai-openai/1.0.0-beta.13 (21; Windows 11; 10.0)",
        "x-ms-client-request-id": "Sanitized"
      },
      "RequestBody": {
        "messages": [
          {
            "role": "user",
            "content": "What does PR complete mean?"
          }
        ],
        "data_sources": [
          {
            "parameters": {
              "endpoint": "https://REDACTED",
              "index_name": "openai-readmes-index",
              "include_contexts": [
                "citations"
              ],
              "authentication": {
                "key": "REDACTED",
                "type": "api_key"
              }
            },
            "type": "azure_search"
          }
        ]
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "c06136aa-955d-482f-ac43-b5e853befae5",
        "Connection": "keep-alive",
        "Content-Length": "11519",
        "Content-Type": "application/json; charset=UTF-8",
        "Date": "Tue, 26 Nov 2024 03:34:26 GMT",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "X-Content-Type-Options": "nosniff",
        "x-envoy-upstream-service-time": "2929",
        "x-ms-client-request-id": "Sanitized",
        "x-ms-region": "East US",
        "x-ratelimit-remaining-requests": "29",
        "x-ratelimit-remaining-tokens": "28848"
      },
      "ResponseBody": {
        "id": "6b9a2cee-f567-4043-b865-03d6a7b7ef96",
        "model": "gpt-4-32k",
        "created": 1732592066,
        "object": "extensions.chat.completion",
        "choices": [
          {
            "index": 0,
            "finish_reason": "stop",
            "message": {
              "role": "assistant",
              "content": "The requested information is not available in the retrieved data. Please try another query or topic.",
              "end_turn": true,
              "context": {
                "citations": [
                  {
                    "content": "## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a [Contributor License Agreement (CLA)][cla] declaring that you have the right to, and actually do, grant us the rights to use your contribution.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate\nthe PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to\ndo this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct][coc]. For more information, see\nthe [Code of Conduct FAQ][coc_faq] or contact [opencode@microsoft.com][coc_contact] with any additional questions or\ncomments.\n\n\n[azure_openai_access]: https://learn.microsoft.com/azure/cognitive-services/openai/overview#how-do-i-get-access-to-azure-openai\n[azopenai_repo]: https://github.com/Azure/azure-sdk-for-go/tree/main/sdk/ai/azopenai\n[azopenai_pkg_go]: https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/ai/azopenai\n[azure_identity]: https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity\n[azure_sub]: https://azure.microsoft.com/free/\n[openai_docs]: https://learn.microsoft.com/azure/cognitive-services/openai\n[openai_key_concepts]: https://learn.microsoft.com/azure/cognitive-services/openai/overview#key-concepts\n[openai_rest_docs]: https://learn.microsoft.com/azure/cognitive-services/openai/reference\n[cla]: https://cla.microsoft.com\n[coc]: https://opensource.microsoft.com/codeofconduct/\n[coc_faq]: https://opensource.microsoft.com/codeofconduct/faq/\n[coc_contact]: mailto:opencode@microsoft.com\n[azure_openai_quickstart]: https://learn.microsoft.com/azure/cognitive-services/openai/quickstart",
                    "title": "Azure OpenAI client module for Go",
                    "url": "REDACTED",
                    "filepath": "azure-go.md",
                    "chunk_id": "0"
                  },
                  {
                    "content": "For a complete sample example, see sample [Chat Completions][sample_get_chat_completions].\n\nFor `function call` sample, see [function call][sample_chat_completion_function_call]. However, they are considered \na legacy feature. Using tools is the preferred way. For more details see sample [tool calls][sample_tool_calls].\n\nFor `Bring Your Own Data` sample, see [Bring Your Own Data][sample_chat_completion_function_call].\n\nPlease refer to the service documentation for a conceptual discussion of [text completion][microsoft_docs_openai_completion].\n\n### Streaming chat completions\n\n```java readme-sample-getChatCompletionsStream\nList chatMessages = new ArrayList&lt;&gt;();\nchatMessages.add(new ChatRequestSystemMessage(\"You are a helpful assistant. You will talk like a pirate.\"));\nchatMessages.add(new ChatRequestUserMessage(\"Can you help me?\"));\nchatMessages.add(new ChatRequestAssistantMessage(\"Of course, me hearty! What can I do for ye?\"));\nchatMessages.add(new ChatRequestUserMessage(\"What's the best way to train a parrot?\"));\n\nclient.getChatCompletionsStream(\"{deploymentOrModelName}\", new ChatCompletionsOptions(chatMessages))\n  .forEach(chatCompletions -&gt; {\n  if (CoreUtils.isNullOrEmpty(chatCompletions.getChoices())) {\n  return;\n  }\n  ChatResponseMessage delta = chatCompletions.getChoices().get(0).getDelta();\n  if (delta.getRole() != null) {\n  System.out.println(\"Role = \" + delta.getRole());\n  }\n  if (delta.getContent() != null) {\n  String content = delta.getContent();\n  System.out.print(content);\n  }\n  });\n```\n\nTo compute tokens in streaming chat completions, see sample [Streaming Chat Completions][sample_get_chat_completions_streaming].\n\n### Text embeddings\n\n```java readme-sample-getEmbedding\nEmbeddingsOptions embeddingsOptions = new EmbeddingsOptions(\n  Arrays.asList(\"Your text string goes here\"));\n\nEmbeddings embeddings = client.getEmbeddings(\"{deploymentOrModelName}\", embeddingsOptions);\n\nfor (EmbeddingItem item : embeddings.getData()) {\n  System.out.printf(\"Index: %d.%n\", item.getPromptIndex());\n  for (Float embedding : item.getEmbedding()) {\n  System.out.printf(\"%f;\", embedding);\n  }\n}\n```\nFor a complete sample example, see sample [Embedding][sample_get_embedding].\n\nPlease refer to the service documentation for a conceptual discussion of [openAI embedding][microsoft_docs_openai_embedding].\n\n### Image Generation\n\n```java readme-sample-imageGeneration\nImageGenerationOptions imageGenerationOptions = new ImageGenerationOptions(\n  \"A drawing of the Seattle skyline in the style of Van Gogh\");\nImageGenerations images = client.getImageGenerations(\"{deploymentOrModelName}\", imageGenerationOptions);\n\nfor (ImageGenerationData imageGenerationData : images.getData()) {\n  System.out.printf(\n  \"Image location URL that provides temporary access to download the generated image is %s.%n\",\n  imageGenerationData.getUrl());\n}",
                    "title": "Azure OpenAI client library for Java",
                    "url": "REDACTED",
                    "filepath": "azure-java.md",
                    "chunk_id": "0"
                  },
                  {
                    "content": "## Key concepts\n\n## Examples\nThe following sections provide several code snippets covering some of the most common OpenAI service tasks, including:\n\n* [Text completions sample](#text-completions \"Text completions\")\n* [Streaming text completions sample](#streaming-text-completions \"Streaming text completions\")\n* [Chat completions sample](#chat-completions \"Chat completions\")\n* [Streaming chat completions sample](#streaming-chat-completions \"Streaming chat completions\")\n* [Embeddings sample](#text-embeddings \"Text Embeddings\")\n* [Image Generation sample](#image-generation \"Image Generation\")\n* [Audio Transcription sample](#audio-transcription \"Audio Transcription\")\n* [Audio Translation sample](#audio-translation \"Audio Translation\")\n\n### Legacy completions\n\nIt is generally preferable to use Chat Completions instead. However, Completions are still supported:\n\n``` java readme-sample-getCompletions\nList prompt = new ArrayList&lt;&gt;();\nprompt.add(\"Say this is a test\");\n\nCompletions completions = client.getCompletions(\"{deploymentOrModelName}\", new CompletionsOptions(prompt));\n\nSystem.out.printf(\"Model ID=%s is created at %s.%n\", completions.getId(), completions.getCreatedAt());\nfor (Choice choice : completions.getChoices()) {\n  System.out.printf(\"Index: %d, Text: %s.%n\", choice.getIndex(), choice.getText());\n}\n```\n\nFor a complete sample example, see sample [Text Completions][sample_get_completions].\n\n### Streaming legacy completions\n\n```java readme-sample-getCompletionsStream\nList prompt = new ArrayList&lt;&gt;();\nprompt.add(\"How to bake a cake?\");\n\nIterableStream completionsStream = client\n  .getCompletionsStream(\"{deploymentOrModelName}\", new CompletionsOptions(prompt));\n\ncompletionsStream\n  .stream()\n  // Remove .skip(1) when using Non-Azure OpenAI API\n  // Note: the first chat completions can be ignored when using Azure OpenAI service which is a known service bug.\n  // TODO: remove .skip(1) when service fix the issue.\n  .skip(1)\n  .forEach(completions -&gt; System.out.print(completions.getChoices().get(0).getText()));\n```\n\nFor a complete sample example, see sample [Streaming Text Completions][sample_get_completions_streaming].\n\n### Chat completions\n\n``` java readme-sample-getChatCompletions\nList chatMessages = new ArrayList&lt;&gt;();\nchatMessages.add(new ChatRequestSystemMessage(\"You are a helpful assistant. You will talk like a pirate.\"));\nchatMessages.add(new ChatRequestUserMessage(\"Can you help me?\"));\nchatMessages.add(new ChatRequestAssistantMessage(\"Of course, me hearty! What can I do for ye?\"));\nchatMessages.add(new ChatRequestUserMessage(\"What's the best way to train a parrot?\"));\n\nChatCompletions chatCompletions = client.getChatCompletions(\"{deploymentOrModelName}\",\n  new ChatCompletionsOptions(chatMessages));\n\nSystem.out.printf(\"Model ID=%s is created at %s.%n\", chatCompletions.getId(), chatCompletions.getCreatedAt());\nfor (ChatChoice choice : chatCompletions.getChoices()) {\n  ChatResponseMessage message = choice.getMessage();\n  System.out.printf(\"Index: %d, Chat Role: %s.%n\", choice.getIndex(), message.getRole());\n  System.out.println(\"Message:\");\n  System.out.println(message.getContent());\n}",
                    "title": "Azure OpenAI client library for Java",
                    "url": "REDACTED",
                    "filepath": "azure-java.md",
                    "chunk_id": "1"
                  },
                  {
                    "content": "### Text To Speech\n\nThe OpenAI service starts supporting `text to speech` with the introduction of `tts` models.\nThe following code snippet shows how to use the service to convert text to speech.\n```java readme-sample-textToSpeech\nString deploymentOrModelId = \"{azure-open-ai-deployment-model-id}\";\nSpeechGenerationOptions options = new SpeechGenerationOptions(\n  \"Today is a wonderful day to build something people love!\",\n  SpeechVoice.ALLOY);\nBinaryData speech = client.generateSpeechFromText(deploymentOrModelId, options);\n// Checkout your generated speech in the file system.\nPath path = Paths.get(\"{your-local-file-path}/speech.wav\");\nFiles.write(path, speech.toBytes());See sample [Text to Speech][sample_text_to_speech] for a complete sample.\nPlease refer to the service documentation for a conceptual discussion of [Text to Speech][microsoft_docs_text_to_speech].\n\n## Troubleshooting\n### Enable client logging\nYou can set the `AZURE_LOG_LEVEL` environment variable to view logging statements made in the client library. For\nexample, setting `AZURE_LOG_LEVEL=2` would show all informational, warning, and error log messages. The log levels can\nbe found here: [log levels][logLevels].\n\n### Default HTTP Client\nAll client libraries by default use the Netty HTTP client. Adding the above dependency will automatically configure\nthe client library to use the Netty HTTP client. Configuring or changing the HTTP client is detailed in the\n[HTTP clients wiki](https://github.com/Azure/azure-sdk-for-java/wiki/HTTP-clients).\n\n### Default SSL library\nAll client libraries, by default, use the Tomcat-native Boring SSL library to enable native-level performance for SSL\noperations. The Boring SSL library is an uber jar containing native libraries for Linux / macOS / Windows, and provides\nbetter performance compared to the default SSL implementation within the JDK. For more information, including how to\nreduce the dependency size, refer to the [performance tuning][performance_tuning] section of the wiki.\n\nFor more details, see [TROUBLESHOOTING][troubleshooting] guideline.\n\n## Next steps\n- Samples are explained in detail [here][samples_readme].\n\n## Contributing\n\nFor details on contributing to this repository, see the [contributing guide](https://github.com/Azure/azure-sdk-for-java/blob/main/CONTRIBUTING.md).\n\n1. Fork it\n1. Create your feature branch (`git checkout -b my-new-feature`)\n1. Commit your changes (`git commit -am 'Add some feature'`)\n1. Push to the branch (`git push origin my-new-feature`)\n1. Create new Pull Request",
                    "title": "Azure OpenAI client library for Java",
                    "url": "REDACTED",
                    "filepath": "azure-java.md",
                    "chunk_id": "3"
                  }
                ]
              }
            }
          }
        ],
        "usage": {
          "prompt_tokens": 5837,
          "completion_tokens": 26,
          "total_tokens": 5863
        }
      }
    }
  ],
  "Variables": {}
}
