{
  "Entries": [
    {
      "RequestUri": "https://api.openai.com/v1/chat/completions",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "119",
        "Content-Type": "application/json",
        "traceparent": "00-4c225c6fbb92f7f47a14d4cdd573cc5b-a82664249c862fae-00",
        "User-Agent": "azsdk-net-AI.OpenAI/1.0.0-alpha.20240301.1 (.NET Framework 4.8.9181.0; Microsoft Windows 10.0.22631 )",
        "x-ms-client-request-id": "a264e61c27740fdde2114e18c8a6aed8",
        "x-ms-return-client-request-id": "true"
      },
      "RequestBody": {
        "messages": [
          {
            "content": "Say this is a test!",
            "role": "user"
          }
        ],
        "model": "gpt-3.5-turbo",
        "logprobs": true,
        "top_logprobs": 3
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "Access-Control-Allow-Origin": "*",
        "Alt-Svc": "h3=\u0022:443\u0022",
        "Cache-Control": "must-revalidate, no-cache",
        "CF-Cache-Status": "DYNAMIC",
        "CF-RAY": "85daec327fd5868f-SEA",
        "Connection": "keep-alive",
        "Content-Length": "5283",
        "Content-Type": "application/json",
        "Date": "Fri, 01 Mar 2024 17:38:47 GMT",
        "openai-model": "gpt-3.5-turbo-0125",
        "openai-organization": "user-eb0z6m0kzogbzxxof1nt9yre",
        "openai-processing-ms": "496",
        "openai-version": "2020-10-01",
        "Server": "cloudflare",
        "Set-Cookie": [
          "__cf_bm=WyJJa9xF2q2E._K4cVd_FA41P.aPx4slOkZVnxMNA04-1709314727-1.0-AWDx\u002B2VcOUgKpTEhNUALXNz1c66Fkdy5z/w9KCat6ewPtA9kN9m7Z4Sre0uppYdwu6olKSdFS2U3FfYfuTw0z5k=; path=/; expires=Fri, 01-Mar-24 18:08:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None",
          "_cfuvid=zONHRluf34SgphWkIk93wP5BYewWhcVzppBQ2KxtLp8-1709314727641-0.0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None"
        ],
        "Strict-Transport-Security": "max-age=15724800; includeSubDomains",
        "x-ratelimit-limit-requests": "10000",
        "x-ratelimit-limit-tokens": "60000",
        "x-ratelimit-remaining-requests": "9999",
        "x-ratelimit-remaining-tokens": "59978",
        "x-ratelimit-reset-requests": "8.64s",
        "x-ratelimit-reset-tokens": "22ms",
        "X-Request-ID": "req_855c395d0cd6c3af0f1ac81037952275"
      },
      "ResponseBody": {
        "id": "chatcmpl-8y18JCKl5PyYcVMgXjiYflNrJXXW4",
        "object": "chat.completion",
        "created": 1709314727,
        "model": "gpt-3.5-turbo-0125",
        "choices": [
          {
            "index": 0,
            "message": {
              "role": "assistant",
              "content": "This is a test!"
            },
            "logprobs": {
              "content": [
                {
                  "token": "This",
                  "logprob": -0.0003236647,
                  "bytes": [
                    84,
                    104,
                    105,
                    115
                  ],
                  "top_logprobs": [
                    {
                      "token": "This",
                      "logprob": -0.0003236647,
                      "bytes": [
                        84,
                        104,
                        105,
                        115
                      ]
                    },
                    {
                      "token": "\u0022This",
                      "logprob": -8.318837,
                      "bytes": [
                        34,
                        84,
                        104,
                        105,
                        115
                      ]
                    },
                    {
                      "token": "Sure",
                      "logprob": -10.417302,
                      "bytes": [
                        83,
                        117,
                        114,
                        101
                      ]
                    }
                  ]
                },
                {
                  "token": " is",
                  "logprob": -1.6240566e-6,
                  "bytes": [
                    32,
                    105,
                    115
                  ],
                  "top_logprobs": [
                    {
                      "token": " is",
                      "logprob": -1.6240566e-6,
                      "bytes": [
                        32,
                        105,
                        115
                      ]
                    },
                    {
                      "token": " sentence",
                      "logprob": -15.307247,
                      "bytes": [
                        32,
                        115,
                        101,
                        110,
                        116,
                        101,
                        110,
                        99,
                        101
                      ]
                    },
                    {
                      "token": " text",
                      "logprob": -15.368931,
                      "bytes": [
                        32,
                        116,
                        101,
                        120,
                        116
                      ]
                    }
                  ]
                },
                {
                  "token": " a",
                  "logprob": -0.00013238314,
                  "bytes": [
                    32,
                    97
                  ],
                  "top_logprobs": [
                    {
                      "token": " a",
                      "logprob": -0.00013238314,
                      "bytes": [
                        32,
                        97
                      ]
                    },
                    {
                      "token": " just",
                      "logprob": -9.339736,
                      "bytes": [
                        32,
                        106,
                        117,
                        115,
                        116
                      ]
                    },
                    {
                      "token": " test",
                      "logprob": -10.377126,
                      "bytes": [
                        32,
                        116,
                        101,
                        115,
                        116
                      ]
                    }
                  ]
                },
                {
                  "token": " test",
                  "logprob": -0.000026537622,
                  "bytes": [
                    32,
                    116,
                    101,
                    115,
                    116
                  ],
                  "top_logprobs": [
                    {
                      "token": " test",
                      "logprob": -0.000026537622,
                      "bytes": [
                        32,
                        116,
                        101,
                        115,
                        116
                      ]
                    },
                    {
                      "token": " Test",
                      "logprob": -11.37027,
                      "bytes": [
                        32,
                        84,
                        101,
                        115,
                        116
                      ]
                    },
                    {
                      "token": " text",
                      "logprob": -12.02706,
                      "bytes": [
                        32,
                        116,
                        101,
                        120,
                        116
                      ]
                    }
                  ]
                },
                {
                  "token": "!",
                  "logprob": -0.00031174798,
                  "bytes": [
                    33
                  ],
                  "top_logprobs": [
                    {
                      "token": "!",
                      "logprob": -0.00031174798,
                      "bytes": [
                        33
                      ]
                    },
                    {
                      "token": ".",
                      "logprob": -8.191524,
                      "bytes": [
                        46
                      ]
                    },
                    {
                      "token": "!\n",
                      "logprob": -11.428084,
                      "bytes": [
                        33,
                        10
                      ]
                    }
                  ]
                }
              ]
            },
            "finish_reason": "stop"
          }
        ],
        "usage": {
          "prompt_tokens": 13,
          "completion_tokens": 5,
          "total_tokens": 18
        },
        "system_fingerprint": "fp_2b778c6b35"
      }
    }
  ],
  "Variables": {
    "RandomSeed": "1885242232"
  }
}
