{
  "Entries": [
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "474",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "evaluation_metric": "fuzzy_match",
            "input": "{{item.query}}",
            "pass_threshold": 1.0,
            "reference": "{{item.query}}",
            "type": "text_similarity",
            "name": "Sanitized"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "17d6dbb4-e658-40b9-a0bd-89aec8086233",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:21 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "131",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "6f5014d0-c244-48dd-ac57-c101f02896fe"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "text_similarity",
            "input": "{{item.query}}",
            "reference": "{{item.query}}",
            "pass_threshold": 1.0,
            "evaluation_metric": "fuzzy_match"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746130462,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d61eaee48190abb6f4d497a23315/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "d0bf91d6-c4ac-4855-8e5e-d2d27aaf946b",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:22 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "728",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "a6f86eaf-a2f9-49e8-8cb6-2a135a9d2665"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d61eaee48190abb6f4d497a23315",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130463,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "428",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "What is",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "d1c49fab-1e1f-4296-80f2-ffc1030c8403",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:23 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "301",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "3bc1b20b-8bd7-4e6c-875b-17dbc74abedf"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "What is",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746130463,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d61fc6948190a426e3542b55776a/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "52c57f50-d3bd-4ced-bed3-c56905cab2d3",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:23 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "103",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "4291d8c6-6039-4dd4-8c2d-ece5aad5c1f0"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d61fc6948190a426e3542b55776a",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130464,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "510",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": [
              {
                "content": "{{item.query}}",
                "role": "user"
              }
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "model": "gpt-4o",
            "name": "Sanitized",
            "passing_labels": [
              "just right"
            ],
            "type": "label_model"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "f0423f17-9855-424d-8e0c-7c96a3fb706f",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:23 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "51",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "02835344-7cd0-4471-b1ca-fc4d798c6c49"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "label_model",
            "model": "gpt-4o",
            "input": [
              {
                "type": "message",
                "role": "user",
                "content": {
                  "type": "input_text",
                  "text": "{{item.query}}"
                }
              }
            ],
            "passing_labels": [
              "just right"
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "sampling_params": null
          }
        ],
        "name": "Sanitized",
        "created_at": 1746130464,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d6204f3c8190996ef5ad530e2155/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "2fabe28b-3901-48ae-9eaf-2bd3b83adaa6",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:23 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "231",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "9a379c56-2324-412e-a61f-23817b280a54"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d6204f3c8190996ef5ad530e2155",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130464,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "426",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "hello",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "770b7982-9e8a-4cfc-af58-250439675848",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:23 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "36",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "115e4e93-fc30-47b6-8dc0-e29d62c7689b"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "hello",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746130464,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d620b7208190a1364f9f854535d5/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "9be104b2-f1df-4c17-95b3-e0f6305ccfc4",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:24 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "188",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "6af21970-1ed5-4682-8802-b0c7c6f192bc"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d620b7208190a1364f9f854535d5",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130464,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d61eaee48190abb6f4d497a23315/runs/evalrun_6813d61f44ac8190864b1794b2e1de7a?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "0357ef18-f4c3-425c-9774-eb9343daa2a1",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:29 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "45",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "04f97ce8-4075-4128-90e0-294aef6f17ab"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d61eaee48190abb6f4d497a23315",
        "report_url": "https://platform.openai.com/evaluations/eval_6813d61eaee48190abb6f4d497a23315?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6813d61f44ac8190864b1794b2e1de7a",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130463,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "similarity-76405dd8-ebd3-4c40-8ded-8a41cd26963c",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d61eaee48190abb6f4d497a23315/runs/evalrun_6813d61f44ac8190864b1794b2e1de7a/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "02f705d9-aa32-4d7c-a556-fb052f719a5b",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:29 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "73",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "e99ee7c4-1f7a-4216-a504-8fadb43f623f"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130469,
            "run_id": "evalrun_6813d61f44ac8190864b1794b2e1de7a",
            "eval_id": "eval_6813d61eaee48190abb6f4d497a23315",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130469,
            "run_id": "evalrun_6813d61f44ac8190864b1794b2e1de7a",
            "eval_id": "eval_6813d61eaee48190abb6f4d497a23315",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130469,
            "run_id": "evalrun_6813d61f44ac8190864b1794b2e1de7a",
            "eval_id": "eval_6813d61eaee48190abb6f4d497a23315",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6813d625294c8190aa4a2fe5abc7583c",
        "last_id": "outputitem_6813d6251dd48190adb63b8d4e4e86ec",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d61fc6948190a426e3542b55776a/runs/evalrun_6813d62025ec8190a0c789592537e73e?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "29e61399-e5a1-4152-b790-8f91ea190e06",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:34 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "43",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "dbc5b751-b423-46f1-86c1-0e8e6b63a371"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d61fc6948190a426e3542b55776a",
        "report_url": "https://platform.openai.com/evaluations/eval_6813d61fc6948190a426e3542b55776a?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6813d62025ec8190a0c789592537e73e",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130464,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 2,
          "passed": 1
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "starts with what is-8e69f84d-d538-47ab-aa16-5cfe2cc5ad92",
            "passed": 1,
            "failed": 2
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d61fc6948190a426e3542b55776a/runs/evalrun_6813d62025ec8190a0c789592537e73e/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "a5aed15f-6c54-42a2-bd43-5c1c5ba7c9c7",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:34 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "65",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "d405338d-5590-41cb-a97b-ccdac543cce5"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130469,
            "run_id": "evalrun_6813d62025ec8190a0c789592537e73e",
            "eval_id": "eval_6813d61fc6948190a426e3542b55776a",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130469,
            "run_id": "evalrun_6813d62025ec8190a0c789592537e73e",
            "eval_id": "eval_6813d61fc6948190a426e3542b55776a",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130469,
            "run_id": "evalrun_6813d62025ec8190a0c789592537e73e",
            "eval_id": "eval_6813d61fc6948190a426e3542b55776a",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6813d625c6588190b0b9c118335f4e21",
        "last_id": "outputitem_6813d625be508190bfc50a6aac1976ed",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d6204f3c8190996ef5ad530e2155/runs/evalrun_6813d6206fc48190a16ac37535d02c2a?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "a2bb65d5-c9b3-489a-bb0a-f9d4df502621",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:39 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "18",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "369ee31c-46a9-41c1-8999-f99e44941b7a"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d6204f3c8190996ef5ad530e2155",
        "report_url": "https://platform.openai.com/evaluations/eval_6813d6204f3c8190996ef5ad530e2155?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6813d6206fc48190a16ac37535d02c2a",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130464,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [
          {
            "model_name": "gpt-4o-2024-11-20",
            "invocation_count": 3,
            "prompt_tokens": 397,
            "completion_tokens": 230,
            "total_tokens": 627,
            "cached_tokens": 0
          }
        ],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "label-81bf469e-9e71-4050-ab95-e067e2c7d6b8",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d6204f3c8190996ef5ad530e2155/runs/evalrun_6813d6206fc48190a16ac37535d02c2a/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "3f3f3411-dfab-48bf-99dc-cfd5d51ce370",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:39 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "49",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "4ae70e5b-52c9-498e-a00b-af1d2281d2db"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130472,
            "run_id": "evalrun_6813d6206fc48190a16ac37535d02c2a",
            "eval_id": "eval_6813d6204f3c8190996ef5ad530e2155",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you create a run?",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Understand the context of the inquiry to provide an appropriate explanation.\",\"conclusion\":\"The query pertains to the construction of a 'run' which has multiple interpretations.\"},{\"description\":\"Clarify and enumerate potential domains or contexts for 'creating a run', such as sports, movies, or software.\",\"conclusion\":\"Identified relevant contexts to provide a tailored response.\"},{\"description\":\"Formulate a concise and complete explanation for one identified context, showing logical progression and brevity.\",\"conclusion\":\"Drafted an explanation in one sentence to meet assumed guidelines.\"}],\"result\":\"just right\"}",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 251,
                    "completion_tokens": 121,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130472,
            "run_id": "evalrun_6813d6206fc48190a16ac37535d02c2a",
            "eval_id": "eval_6813d6204f3c8190996ef5ad530e2155",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you log a model?",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"To decide the appropriate length of the response, I evaluated the complexity of the user's question and provided a detailed yet concise explanation.\",\"conclusion\":\"The response is appropriately detailed to cover the topic comprehensively.\"}],\"result\":\"just right\"}",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 184,
                    "completion_tokens": 54,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130471,
            "run_id": "evalrun_6813d6206fc48190a16ac37535d02c2a",
            "eval_id": "eval_6813d6204f3c8190996ef5ad530e2155",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "What is the capital of France?`''\"</>{}{{]",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Interpret the query provided.\",\"conclusion\":\"The query asks for the capital of France.\"},{\"description\":\"Recall the factual information related to the capital of France.\",\"conclusion\":\"The capital of France is Paris.\"}],\"result\":\"just right\"}",
                      "tool_call_id": null,
                      "tool_calls": null,
                      "function_call": null
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 192,
                    "completion_tokens": 55,
                    "prompt_tokens": 137,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6813d6283ae881909719cc23fa916c58",
        "last_id": "outputitem_6813d6275fd08190b9dccc38b4613b37",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d620b7208190a1364f9f854535d5/runs/evalrun_6813d620d19c8190929305b334d3759c?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "91b2b187-cd34-4fa4-9f4b-235ef3984038",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:45 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "503",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "a2409680-bc89-422a-8e98-da5275fba200"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_6813d620b7208190a1364f9f854535d5",
        "report_url": "https://platform.openai.com/evaluations/eval_6813d620b7208190a1364f9f854535d5?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_6813d620d19c8190929305b334d3759c",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746130464,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 3,
          "passed": 0
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "contains hello-49be34c3-4597-4821-9861-935e9c879768",
            "passed": 0,
            "failed": 3
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_6813d620b7208190a1364f9f854535d5/runs/evalrun_6813d620d19c8190929305b334d3759c/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "af24efce-81a0-4d3a-8f84-a38bc638cc65",
        "azureml-served-by-cluster": "hyena-eastus2-02",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Thu, 01 May 2025 20:14:45 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "198",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "d20ad71d-ab20-4075-a5ad-e97e21ab5dd2"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130470,
            "run_id": "evalrun_6813d620d19c8190929305b334d3759c",
            "eval_id": "eval_6813d620b7208190a1364f9f854535d5",
            "status": "fail",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130470,
            "run_id": "evalrun_6813d620d19c8190929305b334d3759c",
            "eval_id": "eval_6813d620b7208190a1364f9f854535d5",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746130470,
            "run_id": "evalrun_6813d620d19c8190929305b334d3759c",
            "eval_id": "eval_6813d620b7208190a1364f9f854535d5",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_6813d62646708190a0dfdca3a58311e3",
        "last_id": "outputitem_6813d626305881909fd8b2e71ddf315d",
        "has_more": false
      }
    }
  ],
  "Variables": {}
}
