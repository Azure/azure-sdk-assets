{
  "Entries": [
    {
      "RequestUri": "https://api.openai.com/v1/chat/completions",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "119",
        "Content-Type": "application/json",
        "traceparent": "00-08e5eaea8f14703d163bfced99c33d37-14bd90cbc59998ba-00",
        "User-Agent": "azsdk-net-AI.OpenAI/1.0.0-alpha.20240301.1 (.NET Framework 4.8.9181.0; Microsoft Windows 10.0.22631 )",
        "x-ms-client-request-id": "7a05a44655365ff2498cb66a1f8810fd",
        "x-ms-return-client-request-id": "true"
      },
      "RequestBody": {
        "messages": [
          {
            "content": "Say this is a test!",
            "role": "user"
          }
        ],
        "model": "gpt-3.5-turbo",
        "logprobs": true,
        "top_logprobs": 3
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "Access-Control-Allow-Origin": "*",
        "Alt-Svc": "h3=\u0022:443\u0022",
        "Cache-Control": "must-revalidate, no-cache",
        "CF-Cache-Status": "DYNAMIC",
        "CF-RAY": "85daf5ed9965682b-SEA",
        "Connection": "keep-alive",
        "Content-Length": "5236",
        "Content-Type": "application/json",
        "Date": "Fri, 01 Mar 2024 17:45:25 GMT",
        "openai-model": "gpt-3.5-turbo-0125",
        "openai-organization": "user-eb0z6m0kzogbzxxof1nt9yre",
        "openai-processing-ms": "368",
        "openai-version": "2020-10-01",
        "Server": "cloudflare",
        "Strict-Transport-Security": "max-age=15724800; includeSubDomains",
        "x-ratelimit-limit-requests": "10000",
        "x-ratelimit-limit-tokens": "60000",
        "x-ratelimit-remaining-requests": "9998",
        "x-ratelimit-remaining-tokens": "59978",
        "x-ratelimit-reset-requests": "15.357s",
        "x-ratelimit-reset-tokens": "22ms",
        "X-Request-ID": "req_2bffae418bebcbab94e2f859d6e5bc33"
      },
      "ResponseBody": {
        "id": "chatcmpl-8y1EjzBtn4U7KXD3fiCVPXNIN31vd",
        "object": "chat.completion",
        "created": 1709315125,
        "model": "gpt-3.5-turbo-0125",
        "choices": [
          {
            "index": 0,
            "message": {
              "role": "assistant",
              "content": "This is a test!"
            },
            "logprobs": {
              "content": [
                {
                  "token": "This",
                  "logprob": -0.000108788154,
                  "bytes": [
                    84,
                    104,
                    105,
                    115
                  ],
                  "top_logprobs": [
                    {
                      "token": "This",
                      "logprob": -0.000108788154,
                      "bytes": [
                        84,
                        104,
                        105,
                        115
                      ]
                    },
                    {
                      "token": "\u0022This",
                      "logprob": -9.655895,
                      "bytes": [
                        34,
                        84,
                        104,
                        105,
                        115
                      ]
                    },
                    {
                      "token": "Sure",
                      "logprob": -10.870766,
                      "bytes": [
                        83,
                        117,
                        114,
                        101
                      ]
                    }
                  ]
                },
                {
                  "token": " is",
                  "logprob": -1.6240566e-6,
                  "bytes": [
                    32,
                    105,
                    115
                  ],
                  "top_logprobs": [
                    {
                      "token": " is",
                      "logprob": -1.6240566e-6,
                      "bytes": [
                        32,
                        105,
                        115
                      ]
                    },
                    {
                      "token": " Is",
                      "logprob": -15.100155,
                      "bytes": [
                        32,
                        73,
                        115
                      ]
                    },
                    {
                      "token": " sentence",
                      "logprob": -15.429886,
                      "bytes": [
                        32,
                        115,
                        101,
                        110,
                        116,
                        101,
                        110,
                        99,
                        101
                      ]
                    }
                  ]
                },
                {
                  "token": " a",
                  "logprob": -0.000098536635,
                  "bytes": [
                    32,
                    97
                  ],
                  "top_logprobs": [
                    {
                      "token": " a",
                      "logprob": -0.000098536635,
                      "bytes": [
                        32,
                        97
                      ]
                    },
                    {
                      "token": " just",
                      "logprob": -9.527942,
                      "bytes": [
                        32,
                        106,
                        117,
                        115,
                        116
                      ]
                    },
                    {
                      "token": " test",
                      "logprob": -11.051562,
                      "bytes": [
                        32,
                        116,
                        101,
                        115,
                        116
                      ]
                    }
                  ]
                },
                {
                  "token": " test",
                  "logprob": -0.00003070975,
                  "bytes": [
                    32,
                    116,
                    101,
                    115,
                    116
                  ],
                  "top_logprobs": [
                    {
                      "token": " test",
                      "logprob": -0.00003070975,
                      "bytes": [
                        32,
                        116,
                        101,
                        115,
                        116
                      ]
                    },
                    {
                      "token": " Test",
                      "logprob": -11.262781,
                      "bytes": [
                        32,
                        84,
                        101,
                        115,
                        116
                      ]
                    },
                    {
                      "token": " text",
                      "logprob": -12.020603,
                      "bytes": [
                        32,
                        116,
                        101,
                        120,
                        116
                      ]
                    }
                  ]
                },
                {
                  "token": "!",
                  "logprob": -0.0005861567,
                  "bytes": [
                    33
                  ],
                  "top_logprobs": [
                    {
                      "token": "!",
                      "logprob": -0.0005861567,
                      "bytes": [
                        33
                      ]
                    },
                    {
                      "token": ".",
                      "logprob": -7.513798,
                      "bytes": [
                        46
                      ]
                    },
                    {
                      "token": "!\n",
                      "logprob": -11.5942,
                      "bytes": [
                        33,
                        10
                      ]
                    }
                  ]
                }
              ]
            },
            "finish_reason": "stop"
          }
        ],
        "usage": {
          "prompt_tokens": 13,
          "completion_tokens": 5,
          "total_tokens": 18
        },
        "system_fingerprint": "fp_2b778c6b35"
      }
    }
  ],
  "Variables": {
    "RandomSeed": "1016980026"
  }
}
