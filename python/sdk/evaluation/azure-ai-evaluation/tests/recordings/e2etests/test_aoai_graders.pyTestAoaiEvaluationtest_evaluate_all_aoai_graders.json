{
  "Entries": [
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "474",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "evaluation_metric": "fuzzy_match",
            "input": "{{item.query}}",
            "pass_threshold": 1.0,
            "reference": "{{item.query}}",
            "type": "text_similarity",
            "name": "Sanitized"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "c3a5c00c-d32e-42ca-ac20-150291162ac7",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:43 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "741",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "ba7c7c3d-e618-4a09-b569-f54fde88ec8a"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "text_similarity",
            "input": "{{item.query}}",
            "reference": "{{item.query}}",
            "pass_threshold": 1.0,
            "evaluation_metric": "fuzzy_match"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746549283,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a2304348190baf895caec9e96b5/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "360ec36b-e4a7-40f4-9402-e6cd4ad020da",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:44 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "869",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "66853aee-5001-4b2a-96c3-853f50f6e77f"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a2304348190baf895caec9e96b5",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549284,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "428",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "What is",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "50690bbb-ad8b-41e1-b998-0729c832943c",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:45 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "552",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "2acbda1c-ef31-4a51-a113-3cf8283b8f1e"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "What is",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746549284,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a24d47481908cd3b072f2064dbe/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "bc0672fc-fa6f-4682-a64a-5b6479b3cdd6",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:45 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "390",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "416e09f2-6e47-41e6-810a-918f01a78b6a"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a24d47481908cd3b072f2064dbe",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549285,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "510",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": [
              {
                "content": "{{item.query}}",
                "role": "user"
              }
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "model": "gpt-4o",
            "name": "Sanitized",
            "passing_labels": [
              "just right"
            ],
            "type": "label_model"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "beacd262-0f0c-4592-bac0-f8240a176b86",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:45 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "39",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "95babe83-26f3-4f4a-8a90-3b6f529886ec"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "label_model",
            "model": "gpt-4o",
            "input": [
              {
                "type": "message",
                "role": "user",
                "content": {
                  "type": "input_text",
                  "text": "{{item.query}}"
                }
              }
            ],
            "passing_labels": [
              "just right"
            ],
            "labels": [
              "too short",
              "just right",
              "too long"
            ],
            "sampling_params": null
          }
        ],
        "name": "Sanitized",
        "created_at": 1746549285,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a25eb2c8190b90d077a890ec4d9/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "0eaf2b11-90d4-4e14-9742-b9acaa38f8be",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:45 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "111",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "30f70360-1a72-446f-af1b-b4044bb99eab"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a25eb2c8190b90d077a890ec4d9",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549286,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "426",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source_config": {
          "type": "custom",
          "item_schema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string"
              },
              "context": {
                "type": "string"
              },
              "response": {
                "type": "string"
              },
              "ground_truth": {
                "type": "string"
              }
            },
            "required": [
              "query",
              "context",
              "response",
              "ground_truth"
            ]
          }
        },
        "testing_criteria": [
          {
            "input": "{{item.query}}",
            "name": "Sanitized",
            "operation": "like",
            "reference": "hello",
            "type": "string_check"
          }
        ],
        "metadata": {
          "is_foundry_eval": "true"
        }
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "b444e3b9-f607-45a0-b48d-09c1f234bc59",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:46 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "635",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "f6e8b34e-6392-41ad-8ecb-f29ff24401f9"
      },
      "ResponseBody": {
        "object": "eval",
        "id": "Sanitized",
        "data_source_config": {
          "type": "custom",
          "schema": {
            "type": "object",
            "properties": {
              "item": {
                "type": "object",
                "properties": {
                  "query": {
                    "type": "string"
                  },
                  "context": {
                    "type": "string"
                  },
                  "response": {
                    "type": "string"
                  },
                  "ground_truth": {
                    "type": "string"
                  }
                },
                "required": [
                  "query",
                  "context",
                  "response",
                  "ground_truth"
                ]
              }
            },
            "required": [
              "item"
            ]
          }
        },
        "testing_criteria": [
          {
            "name": "Sanitized",
            "id": "Sanitized",
            "type": "string_check",
            "input": "{{item.query}}",
            "reference": "hello",
            "operation": "like"
          }
        ],
        "name": "Sanitized",
        "created_at": 1746549286,
        "metadata": {
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a2631a081908ee1fd296c0f95b7/runs?api-version=2025-04-01-preview",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Length": "3320",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": {
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        },
        "name": "Sanitized"
      },
      "StatusCode": 201,
      "ResponseHeaders": {
        "apim-request-id": "8adc6e9a-97fb-443f-8b5c-ed568ad779ca",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:46 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "103",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "502dc7fc-7a6f-46fa-b02c-dc2706ef1ff8"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a2631a081908ee1fd296c0f95b7",
        "report_url": "https://ai.azure.com/resource/evaluation",
        "status": "queued",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549286,
        "result_counts": {
          "total": 0,
          "errored": 0,
          "failed": 0,
          "passed": 0
        },
        "per_model_usage": null,
        "per_testing_criteria_results": null,
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a2304348190baf895caec9e96b5/runs/evalrun_681a3a245818819098c0d9d025b23e1e?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "7ee169e2-7aef-43ab-a106-0657d2f9554f",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:52 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "18",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "fe8461df-99ef-482c-ba74-a8941e2fe428"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a2304348190baf895caec9e96b5",
        "report_url": "https://platform.openai.com/evaluations/eval_681a3a2304348190baf895caec9e96b5?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a3a245818819098c0d9d025b23e1e",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549284,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "similarity-c71d1cbf-b724-48ce-9537-bf98d9497c92",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a2304348190baf895caec9e96b5/runs/evalrun_681a3a245818819098c0d9d025b23e1e/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "45e8910f-0d62-43e5-9420-7cb8cba7b81e",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:52 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "48",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "d1392340-d8a4-4c2b-b23d-40f03ec84de4"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549290,
            "run_id": "evalrun_681a3a245818819098c0d9d025b23e1e",
            "eval_id": "eval_681a3a2304348190baf895caec9e96b5",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549290,
            "run_id": "evalrun_681a3a245818819098c0d9d025b23e1e",
            "eval_id": "eval_681a3a2304348190baf895caec9e96b5",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549290,
            "run_id": "evalrun_681a3a245818819098c0d9d025b23e1e",
            "eval_id": "eval_681a3a2304348190baf895caec9e96b5",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a3a2acf108190828ec932d5919e9b",
        "last_id": "outputitem_681a3a2ac65481909134eae68237b697",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a24d47481908cd3b072f2064dbe/runs/evalrun_681a3a2574dc8190ab1c3cf182c49224?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "fb4088c4-38ad-4a20-86bb-a4029db2b9ed",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:57 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "31",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "36dcd5a9-4ec4-4162-b351-ff2d35b8f458"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a24d47481908cd3b072f2064dbe",
        "report_url": "https://platform.openai.com/evaluations/eval_681a3a24d47481908cd3b072f2064dbe?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a3a2574dc8190ab1c3cf182c49224",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549285,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 2,
          "passed": 1
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "starts with what is-61093073-67ee-48d0-b167-9150824e666a",
            "passed": 1,
            "failed": 2
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a24d47481908cd3b072f2064dbe/runs/evalrun_681a3a2574dc8190ab1c3cf182c49224/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "ccd0b38f-3100-4458-ac8c-cb2f73a4b953",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:34:57 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "101",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "c490800b-829c-417a-8777-b1f4d4789730"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549291,
            "run_id": "evalrun_681a3a2574dc8190ab1c3cf182c49224",
            "eval_id": "eval_681a3a24d47481908cd3b072f2064dbe",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549291,
            "run_id": "evalrun_681a3a2574dc8190ab1c3cf182c49224",
            "eval_id": "eval_681a3a24d47481908cd3b072f2064dbe",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549291,
            "run_id": "evalrun_681a3a2574dc8190ab1c3cf182c49224",
            "eval_id": "eval_681a3a24d47481908cd3b072f2064dbe",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a3a2bd30881908a2b576f83b84dd5",
        "last_id": "outputitem_681a3a2bc7a481908376385575634600",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a25eb2c8190b90d077a890ec4d9/runs/evalrun_681a3a2606e08190adee22ad0b286975?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "f915b152-699a-49d8-84ad-2e27b65e8a0c",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:35:01 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "125",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "85725747-c9bb-4165-adb4-0ef4eb327849"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a25eb2c8190b90d077a890ec4d9",
        "report_url": "https://platform.openai.com/evaluations/eval_681a3a25eb2c8190b90d077a890ec4d9?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a3a2606e08190adee22ad0b286975",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549286,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 0,
          "passed": 3
        },
        "per_model_usage": [
          {
            "model_name": "gpt-4o-2024-11-20",
            "invocation_count": 3,
            "prompt_tokens": 397,
            "completion_tokens": 222,
            "total_tokens": 619,
            "cached_tokens": 0
          }
        ],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "label-d711d354-90f4-422c-a967-9a605062e9a0",
            "passed": 3,
            "failed": 0
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a25eb2c8190b90d077a890ec4d9/runs/evalrun_681a3a2606e08190adee22ad0b286975/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "370c4f30-730c-4e16-886e-23798675b73a",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:35:02 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "161",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "53b3d355-8db7-4002-a03a-aa6390de2d2e"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549293,
            "run_id": "evalrun_681a3a2606e08190adee22ad0b286975",
            "eval_id": "eval_681a3a25eb2c8190b90d077a890ec4d9",
            "status": "pass",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "What is the capital of France?`''\"</>{}{{]"
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Identify the question asking about the capital city of a specific country, namely France.\",\"conclusion\":\"The capital city of France is Paris.\"},{\"description\":\"Evaluate the response length appropriateness based on current context and information provided.\",\"conclusion\":\"Given the simplicity of the question, a concise one-word answer is acceptable.\"}],\"result\":\"just right\"}"
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 213,
                    "completion_tokens": 76,
                    "prompt_tokens": 137,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549293,
            "run_id": "evalrun_681a3a2606e08190adee22ad0b286975",
            "eval_id": "eval_681a3a25eb2c8190b90d077a890ec4d9",
            "status": "pass",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you log a model?"
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"Analyze the question and determine its intent.\",\"conclusion\":\"The question asks about techniques to log details about a model, most likely in the context of machine learning.\"},{\"description\":\"Provide an explanation based on typical methodology.\",\"conclusion\":\"Explain both MLflow model logging and general logging approaches to suit various contexts.\"}],\"result\":\"just right\"}"
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 205,
                    "completion_tokens": 75,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549293,
            "run_id": "evalrun_681a3a2606e08190adee22ad0b286975",
            "eval_id": "eval_681a3a25eb2c8190b90d077a890ec4d9",
            "status": "pass",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": {
                  "input": [
                    {
                      "role": "user",
                      "content": "How do you create a run?"
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "{\"steps\":[{\"description\":\"The term 'run' could have multiple interpretations depending on context.\",\"conclusion\":\"'Run' needs clarification for an accurate answer.\"},{\"description\":\"Common interpretations include organizing an athletic event, executing a program, or performing sequential steps.\",\"conclusion\":\"Clarification context allows for tailored instructions.\"}],\"result\":\"just right\"}"
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-11-20",
                  "usage": {
                    "total_tokens": 201,
                    "completion_tokens": 71,
                    "prompt_tokens": 130,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 4096,
                  "top_p": 1.0,
                  "seed": null
                },
                "passed": true,
                "score": 1.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a3a2db23c8190a4ff5fe062ac0546",
        "last_id": "outputitem_681a3a2d9a148190b04f960f923be4ef",
        "has_more": false
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a2631a081908ee1fd296c0f95b7/runs/evalrun_681a3a26e54c81909fac405545d5cd63?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "95a490f5-dc8b-423e-9eaf-bc7ad06c106e",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:35:07 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "911",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "31563afc-cf22-456f-96b8-a73cd319372f"
      },
      "ResponseBody": {
        "object": "eval.run",
        "id": "Sanitized",
        "eval_id": "eval_681a3a2631a081908ee1fd296c0f95b7",
        "report_url": "https://platform.openai.com/evaluations/eval_681a3a2631a081908ee1fd296c0f95b7?project_id=238f6a2e60ea43c6b315f40214fe3586&run_id=evalrun_681a3a26e54c81909fac405545d5cd63",
        "status": "completed",
        "model": null,
        "name": "Sanitized",
        "created_at": 1746549286,
        "result_counts": {
          "total": 3,
          "errored": 0,
          "failed": 3,
          "passed": 0
        },
        "per_model_usage": [],
        "per_testing_criteria_results": [
          {
            "testing_criteria": "contains hello-071d7f4e-98e3-4a6e-b816-2cd4d8041ee6",
            "passed": 0,
            "failed": 3
          }
        ],
        "data_source": {
          "type": "jsonl",
          "source": {
            "type": "file_content",
            "content": [
              {
                "item": {
                  "query": "How do you create a run?",
                  "context": "AML API only",
                  "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "How do you log a model?",
                  "context": "Logging can be done using any OSS Sdk",
                  "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
                  "ground_truth": "Paris is the capital of France."
                }
              },
              {
                "item": {
                  "query": "What is the capital of France?`''\"</>{}{{]",
                  "context": "France is in Europe",
                  "response": "Paris is the capital of France.",
                  "ground_truth": "Paris is the capital of France."
                }
              }
            ]
          }
        },
        "error": null,
        "metadata": {
          "sample_generation": "off",
          "file_format": "jsonl",
          "is_foundry_eval": "true"
        }
      }
    },
    {
      "RequestUri": "https://Sanitized.openai.azure.com/openai/evals/eval_681a3a2631a081908ee1fd296c0f95b7/runs/evalrun_681a3a26e54c81909fac405545d5cd63/output_items?api-version=2025-04-01-preview",
      "RequestMethod": "GET",
      "RequestHeaders": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip, deflate",
        "api-key": "Sanitized",
        "Connection": "keep-alive",
        "Content-Type": "application/json",
        "User-Agent": "AzureOpenAI/Python 1.72.0",
        "X-Stainless-Arch": "x64",
        "X-Stainless-Async": "async:asyncio",
        "X-Stainless-Lang": "python",
        "X-Stainless-OS": "Other:XXX",
        "X-Stainless-Package-Version": "vX.X.X",
        "X-Stainless-Runtime": "CPython",
        "X-Stainless-Runtime-Version": "3.X.X"
      },
      "RequestBody": null,
      "StatusCode": 200,
      "ResponseHeaders": {
        "apim-request-id": "10b8b195-6cad-47db-8441-99c84fce1e69",
        "azureml-served-by-cluster": "hyena-eastus2-01",
        "Content-Encoding": "gzip",
        "Content-Type": "application/json",
        "Date": "Tue, 06 May 2025 16:35:07 GMT",
        "openai-organization": "Azure OpenAI",
        "openai-processing-ms": "49",
        "openai-version": "2020-10-01",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "Transfer-Encoding": "chunked",
        "Vary": "Accept-Encoding",
        "X-Content-Type-Options": "nosniff",
        "x-ms-region": "East US 2",
        "X-Request-ID": "fdd1960c-07d4-4051-a4cf-62b9c8f60275"
      },
      "ResponseBody": {
        "object": "list",
        "data": [
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549293,
            "run_id": "evalrun_681a3a26e54c81909fac405545d5cd63",
            "eval_id": "eval_681a3a2631a081908ee1fd296c0f95b7",
            "status": "fail",
            "_datasource_item_content_hash": "5a41dda8f9afa7a7f46deb5040a11aacb2cb360fbfbce1c550b075e07898e5c5",
            "datasource_item_id": 2,
            "datasource_item": {
              "query": "What is the capital of France?`''\"</>{}{{]",
              "context": "France is in Europe",
              "response": "Paris is the capital of France.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549293,
            "run_id": "evalrun_681a3a26e54c81909fac405545d5cd63",
            "eval_id": "eval_681a3a2631a081908ee1fd296c0f95b7",
            "status": "fail",
            "_datasource_item_content_hash": "3920f787a5bbab5152368e46d6202ff79cd9ed5e53532e1d541d5991d8a79c0f",
            "datasource_item_id": 1,
            "datasource_item": {
              "query": "How do you log a model?",
              "context": "Logging can be done using any OSS Sdk",
              "response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          },
          {
            "object": "eval.run.output_item",
            "id": "Sanitized",
            "created_at": 1746549293,
            "run_id": "evalrun_681a3a26e54c81909fac405545d5cd63",
            "eval_id": "eval_681a3a2631a081908ee1fd296c0f95b7",
            "status": "fail",
            "_datasource_item_content_hash": "c460e6ebb57e37d316f208f8d381859312ea1da1926fa7278c0a814fc7254ca9",
            "datasource_item_id": 0,
            "datasource_item": {
              "query": "How do you create a run?",
              "context": "AML API only",
              "response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.",
              "ground_truth": "Paris is the capital of France."
            },
            "results": [
              {
                "name": "Sanitized",
                "sample": null,
                "passed": false,
                "score": 0.0
              }
            ]
          }
        ],
        "first_id": "outputitem_681a3a2d25188190bfa41a455bb58d59",
        "last_id": "outputitem_681a3a2d1ccc8190a5a04c3294f8bf0a",
        "has_more": false
      }
    }
  ],
  "Variables": {}
}
