{
  "Entries": [
    {
      "RequestUri": "https://REDACTED/v1/completions",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Authorization": "Sanitized",
        "Content-Length": "103",
        "Content-Type": "application/json",
        "Date": "Tue, 21 May 2024 22:40:40 GMT",
        "User-Agent": "azsdk-java-azure-ai-openai/1.0.0-beta.9 (11.0.21; Windows 11; 10.0)",
        "x-ms-client-request-id": "Sanitized"
      },
      "RequestBody": {
        "prompt": [
          "Say this is a test"
        ],
        "max_tokens": 1024,
        "n": 3,
        "logprobs": 1,
        "model": "gpt-3.5-turbo-instruct"
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "Access-Control-Allow-Origin": "*",
        "Alt-Svc": "h3=\":443\"",
        "Cache-Control": "must-revalidate, no-cache",
        "CF-Cache-Status": "DYNAMIC",
        "CF-RAY": "887811d12ffd3076-SEA",
        "Connection": "keep-alive",
        "Content-Length": "1775",
        "Content-Type": "application/json",
        "Date": "Tue, 21 May 2024 22:40:41 GMT",
        "openai-model": "gpt-3.5-turbo-instruct",
        "openai-organization": "msft-finetuning-2",
        "openai-processing-ms": "242",
        "openai-version": "2020-10-01",
        "Server": "cloudflare",
        "Strict-Transport-Security": "max-age=15724800; includeSubDomains",
        "x-ratelimit-limit-requests": "3500",
        "x-ratelimit-limit-tokens": "90000",
        "x-ratelimit-remaining-requests": "3499",
        "x-ratelimit-remaining-tokens": "86923",
        "x-ratelimit-reset-requests": "17ms",
        "x-ratelimit-reset-tokens": "2.05s",
        "X-Request-ID": "req_331791b8cbb53c1f334ee3f1d068fee0"
      },
      "ResponseBody": {
        "id": "Sanitized",
        "object": "text_completion",
        "created": 1716331241,
        "model": "gpt-3.5-turbo-instruct",
        "choices": [
          {
            "text": "\n\nOkay. This is a test.",
            "index": 0,
            "logprobs": {
              "tokens": [
                "\n\n",
                "Okay",
                ".",
                " This",
                " is",
                " a",
                " test",
                "."
              ],
              "token_logprobs": [
                -0.87005293,
                -5.405534,
                -2.1716087,
                -0.29634264,
                -0.012134973,
                -0.0015744948,
                -0.00048596508,
                -0.036912173
              ],
              "top_logprobs": [
                {
                  "\n\n": -0.87005293
                },
                {
                  "This": -0.36969376
                },
                {
                  ",": -0.5606506
                },
                {
                  " This": -0.29634264
                },
                {
                  " is": -0.012134973
                },
                {
                  " a": -0.0015744948
                },
                {
                  " test": -0.00048596508
                },
                {
                  ".": -0.036912173
                }
              ],
              "text_offset": [
                18,
                20,
                24,
                25,
                30,
                33,
                35,
                40
              ]
            },
            "finish_reason": "stop"
          },
          {
            "text": "\n\n\nThis is a test.",
            "index": 1,
            "logprobs": {
              "tokens": [
                "\n\n",
                "\n",
                "This",
                " is",
                " a",
                " test",
                "."
              ],
              "token_logprobs": [
                -0.87005293,
                -1.8584614,
                -0.06939239,
                -0.03494781,
                -0.009101037,
                -0.00040815072,
                -0.033807408
              ],
              "top_logprobs": [
                {
                  "\n\n": -0.87005293
                },
                {
                  "This": -0.36969376
                },
                {
                  "This": -0.06939239
                },
                {
                  " is": -0.03494781
                },
                {
                  " a": -0.009101037
                },
                {
                  " test": -0.00040815072
                },
                {
                  ".": -0.033807408
                }
              ],
              "text_offset": [
                18,
                20,
                21,
                25,
                28,
                30,
                35
              ]
            },
            "finish_reason": "stop"
          },
          {
            "text": "\nThe quick brown fox jumps over the lazy dog.",
            "index": 2,
            "logprobs": {
              "tokens": [
                "\n",
                "The",
                " quick",
                " brown",
                " fox",
                " jumps",
                " over",
                " the",
                " lazy",
                " dog",
                "."
              ],
              "token_logprobs": [
                -1.5569178,
                -5.6399097,
                -2.8661106,
                -0.0010919967,
                -0.0025324987,
                -0.1211948,
                -0.00012892624,
                -0.000318185,
                -1.7239736E-05,
                -0.00030793346,
                -0.14119022
              ],
              "top_logprobs": [
                {
                  "\n\n": -0.87005293
                },
                {
                  "\n": -0.5821373
                },
                {
                  " sentence": -0.4475887
                },
                {
                  " brown": -0.0010919967
                },
                {
                  " fox": -0.0025324987
                },
                {
                  " jumps": -0.1211948
                },
                {
                  " over": -0.00012892624
                },
                {
                  " the": -0.000318185
                },
                {
                  " lazy": -1.7239736E-05
                },
                {
                  " dog": -0.00030793346
                },
                {
                  ".": -0.14119022
                }
              ],
              "text_offset": [
                18,
                19,
                22,
                28,
                34,
                38,
                44,
                49,
                53,
                58,
                62
              ]
            },
            "finish_reason": "stop"
          }
        ],
        "usage": {
          "prompt_tokens": 5,
          "completion_tokens": 26,
          "total_tokens": 31
        }
      }
    }
  ],
  "Variables": {}
}
