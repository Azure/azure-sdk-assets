{
  "Entries": [
    {
      "RequestUri": "https://REDACTED/computervision/imageanalysis:analyze?api-version=2023-10-01\u0026features=denseCaptions\u0026gender-neutral-caption=true",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Content-Length": "18",
        "Content-Type": "application/json",
        "Date": "Fri, 09 Feb 2024 19:26:37 GMT",
        "Ocp-Apim-Subscription-Key": "REDACTED",
        "User-Agent": "azsdk-java-azure-ai-vision-imageanalysis/1.0.0-beta.2 (11.0.20; Windows 11; 10.0)",
        "x-ms-client-request-id": "2123fe2d-91bb-4610-909c-808985602135"
      },
      "RequestBody": {
        "url": "REDACTED"
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "api-supported-versions": "4.0-pre1,2022-07-31-preview,2022-10-12-preview,2023-02-01-preview,2023-04-01-preview,2023-06-01-preview,2023-07-01-preview,2023-10-01,2024-02-01",
        "apim-request-id": "0224da19-7370-4b20-a087-81f0b81676c4",
        "Content-Length": "1334",
        "Content-Type": "application/json; charset=utf-8",
        "CSP-Billing-Usage": "CognitiveServices.ComputerVision.Transaction=1",
        "Date": "Fri, 09 Feb 2024 19:26:36 GMT",
        "ms-vision-response-time-input-processed": "1000",
        "ms-vision-response-time-input-received": "104",
        "request-id": "0224da19-7370-4b20-a087-81f0b81676c4",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "X-Content-Type-Options": "nosniff",
        "x-envoy-upstream-service-time": "1108",
        "x-ms-region": "East US"
      },
      "ResponseBody": {
        "modelVersion": "2023-10-01",
        "denseCaptionsResult": {
          "values": [
            {
              "text": "a person wearing a mask sitting at a table with a laptop",
              "confidence": 0.8500158786773682,
              "boundingBox": {
                "x": 0,
                "y": 0,
                "w": 864,
                "h": 576
              }
            },
            {
              "text": "a person using a laptop",
              "confidence": 0.7729847431182861,
              "boundingBox": {
                "x": 293,
                "y": 383,
                "w": 195,
                "h": 100
              }
            },
            {
              "text": "a person wearing a face mask",
              "confidence": 0.8215275406837463,
              "boundingBox": {
                "x": 383,
                "y": 233,
                "w": 275,
                "h": 336
              }
            },
            {
              "text": "a close-up of a green chair",
              "confidence": 0.8764728903770447,
              "boundingBox": {
                "x": 616,
                "y": 211,
                "w": 164,
                "h": 249
              }
            },
            {
              "text": "a person wearing a colorful cloth face mask",
              "confidence": 0.709149181842804,
              "boundingBox": {
                "x": 473,
                "y": 294,
                "w": 68,
                "h": 56
              }
            },
            {
              "text": "a person using a laptop",
              "confidence": 0.7638993859291077,
              "boundingBox": {
                "x": 288,
                "y": 211,
                "w": 151,
                "h": 244
              }
            },
            {
              "text": "a person wearing a colorful fabric face mask",
              "confidence": 0.7735569477081299,
              "boundingBox": {
                "x": 433,
                "y": 240,
                "w": 180,
                "h": 236
              }
            },
            {
              "text": "a close-up of a laptop on a table",
              "confidence": 0.8535196781158447,
              "boundingBox": {
                "x": 115,
                "y": 443,
                "w": 476,
                "h": 125
              }
            },
            {
              "text": "a person wearing a face mask",
              "confidence": 0.8328292965888977,
              "boundingBox": {
                "x": 0,
                "y": 0,
                "w": 775,
                "h": 433
              }
            },
            {
              "text": "a close up of a text",
              "confidence": 0.640383780002594,
              "boundingBox": {
                "x": 714,
                "y": 493,
                "w": 130,
                "h": 80
              }
            }
          ]
        },
        "metadata": {
          "width": 864,
          "height": 576
        }
      }
    },
    {
      "RequestUri": "https://REDACTED/computervision/imageanalysis:analyze?api-version=2023-10-01\u0026features=smartCrops\u0026smartcrops-aspect-ratios=0.9%2C1.33",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Content-Length": "18",
        "Content-Type": "application/json",
        "Date": "Fri, 09 Feb 2024 19:26:38 GMT",
        "Ocp-Apim-Subscription-Key": "REDACTED",
        "User-Agent": "azsdk-java-azure-ai-vision-imageanalysis/1.0.0-beta.2 (11.0.20; Windows 11; 10.0)",
        "x-ms-client-request-id": "84c1e421-6cbf-4a89-8130-9e59d1830038"
      },
      "RequestBody": {
        "url": "REDACTED"
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "api-supported-versions": "4.0-pre1,2022-07-31-preview,2022-10-12-preview,2023-02-01-preview,2023-04-01-preview,2023-06-01-preview,2023-07-01-preview,2023-10-01,2024-02-01",
        "apim-request-id": "a806a2d2-5b61-4f91-b8d9-394d35ddfca8",
        "Content-Length": "231",
        "Content-Type": "application/json; charset=utf-8",
        "CSP-Billing-Usage": "CognitiveServices.ComputerVision.Transaction=1",
        "Date": "Fri, 09 Feb 2024 19:26:37 GMT",
        "ms-vision-response-time-input-processed": "229",
        "ms-vision-response-time-input-received": "99",
        "request-id": "a806a2d2-5b61-4f91-b8d9-394d35ddfca8",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "X-Content-Type-Options": "nosniff",
        "x-envoy-upstream-service-time": "332",
        "x-ms-region": "East US"
      },
      "ResponseBody": {
        "modelVersion": "2023-10-01",
        "metadata": {
          "width": 864,
          "height": 576
        },
        "smartCropsResult": {
          "values": [
            {
              "aspectRatio": 0.9,
              "boundingBox": {
                "x": 238,
                "y": 0,
                "w": 511,
                "h": 568
              }
            },
            {
              "aspectRatio": 1.33,
              "boundingBox": {
                "x": 54,
                "y": 0,
                "w": 760,
                "h": 571
              }
            }
          ]
        }
      }
    },
    {
      "RequestUri": "https://REDACTED/computervision/imageanalysis:analyze?api-version=2023-10-01\u0026features=tags\u0026language=en",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Content-Length": "18",
        "Content-Type": "application/json",
        "Date": "Fri, 09 Feb 2024 19:26:38 GMT",
        "Ocp-Apim-Subscription-Key": "REDACTED",
        "User-Agent": "azsdk-java-azure-ai-vision-imageanalysis/1.0.0-beta.2 (11.0.20; Windows 11; 10.0)",
        "x-ms-client-request-id": "8ef106a4-eb24-4cf0-b3e2-a0011c1565cf"
      },
      "RequestBody": {
        "url": "REDACTED"
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "api-supported-versions": "4.0-pre1,2022-07-31-preview,2022-10-12-preview,2023-02-01-preview,2023-04-01-preview,2023-06-01-preview,2023-07-01-preview,2023-10-01,2024-02-01",
        "apim-request-id": "cdc57f27-4cdc-40b9-b171-dc3d047627af",
        "Content-Length": "797",
        "Content-Type": "application/json; charset=utf-8",
        "CSP-Billing-Usage": "CognitiveServices.ComputerVision.Transaction=1",
        "Date": "Fri, 09 Feb 2024 19:26:37 GMT",
        "ms-vision-response-time-input-processed": "130",
        "ms-vision-response-time-input-received": "26",
        "request-id": "cdc57f27-4cdc-40b9-b171-dc3d047627af",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "X-Content-Type-Options": "nosniff",
        "x-envoy-upstream-service-time": "159",
        "x-ms-region": "East US"
      },
      "ResponseBody": {
        "modelVersion": "2023-10-01",
        "metadata": {
          "width": 864,
          "height": 576
        },
        "tagsResult": {
          "values": [
            {
              "name": "furniture",
              "confidence": 0.9874445199966431
            },
            {
              "name": "clothing",
              "confidence": 0.9792501926422119
            },
            {
              "name": "person",
              "confidence": 0.9427268505096436
            },
            {
              "name": "houseplant",
              "confidence": 0.9400016069412231
            },
            {
              "name": "desk",
              "confidence": 0.9182863235473633
            },
            {
              "name": "indoor",
              "confidence": 0.8963587284088135
            },
            {
              "name": "laptop",
              "confidence": 0.8781813383102417
            },
            {
              "name": "computer",
              "confidence": 0.8481525182723999
            },
            {
              "name": "sitting",
              "confidence": 0.8134784698486328
            },
            {
              "name": "wall",
              "confidence": 0.7511615753173828
            },
            {
              "name": "woman",
              "confidence": 0.7410731911659241
            },
            {
              "name": "table",
              "confidence": 0.6811168789863586
            },
            {
              "name": "plant",
              "confidence": 0.6445199847221375
            },
            {
              "name": "using",
              "confidence": 0.5358931422233582
            }
          ]
        }
      }
    },
    {
      "RequestUri": "https://REDACTED/computervision/imageanalysis:analyze?api-version=2023-10-01\u0026features=people",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json",
        "Content-Length": "18",
        "Content-Type": "application/json",
        "Date": "Fri, 09 Feb 2024 19:26:39 GMT",
        "Ocp-Apim-Subscription-Key": "REDACTED",
        "User-Agent": "azsdk-java-azure-ai-vision-imageanalysis/1.0.0-beta.2 (11.0.20; Windows 11; 10.0)",
        "x-ms-client-request-id": "3ae62dc5-138d-4dcb-b90d-d6a26e900282"
      },
      "RequestBody": {
        "url": "REDACTED"
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "api-supported-versions": "4.0-pre1,2022-07-31-preview,2022-10-12-preview,2023-02-01-preview,2023-04-01-preview,2023-06-01-preview,2023-07-01-preview,2023-10-01,2024-02-01",
        "apim-request-id": "9f6a6dd4-83a9-4fb7-bbb3-bbbd82081c05",
        "Content-Length": "261",
        "Content-Type": "application/json; charset=utf-8",
        "CSP-Billing-Usage": "CognitiveServices.ComputerVision.Transaction=1",
        "Date": "Fri, 09 Feb 2024 19:26:37 GMT",
        "ms-vision-response-time-input-processed": "330",
        "ms-vision-response-time-input-received": "98",
        "request-id": "9f6a6dd4-83a9-4fb7-bbb3-bbbd82081c05",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "X-Content-Type-Options": "nosniff",
        "x-envoy-upstream-service-time": "431",
        "x-ms-region": "East US"
      },
      "ResponseBody": {
        "modelVersion": "2023-10-01",
        "metadata": {
          "width": 864,
          "height": 576
        },
        "peopleResult": {
          "values": [
            {
              "boundingBox": {
                "x": 395,
                "y": 241,
                "w": 261,
                "h": 333
              },
              "confidence": 0.9602553248405457
            },
            {
              "boundingBox": {
                "x": 831,
                "y": 246,
                "w": 31,
                "h": 255
              },
              "confidence": 0.0016505217645317316
            }
          ]
        }
      }
    }
  ],
  "Variables": {}
}
