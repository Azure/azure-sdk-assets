# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import uuid
import re
import json
import os
from datetime import datetime
from typing import Optional, Dict
from enum import Enum
from azure.ai.contentunderstanding.models import ContentAnalyzer, ContentAnalyzerConfig, FieldSchema, FieldDefinition
from azure.ai.contentunderstanding.models import GenerationMethod, FieldType, AnalysisMode, ProcessingLocation


class PollerType(Enum):
    """Enum to distinguish different types of pollers for operation ID extraction."""
    ANALYZER_CREATION = "analyzer_creation"
    ANALYZE_CALL = "analyze_call"


def generate_analyzer_id() -> str:
    """Generate a unique analyzer ID with current date, time, and GUID."""
    now = datetime.now()
    date_str = now.strftime("%Y%m%d")
    time_str = now.strftime("%H%M%S")
    guid = str(uuid.uuid4()).replace("-", "")[:8]
    return f"python-sdk-test-analyzer-{date_str}-{time_str}-{guid}"


def extract_operation_id_from_poller(poller, poller_type: PollerType) -> str:
    """Extract operation ID from an LROPoller or AsyncLROPoller.
    
    The poller stores the initial response in `_initial_response`, which contains
    the Operation-Location header. The extraction pattern depends on the poller type:
    - AnalyzerCreation: https://endpoint/contentunderstanding/operations/{operation_id}?api-version=...
    - AnalyzeCall: https://endpoint/contentunderstanding/analyzerResults/{operation_id}?api-version=...
    
    Args:
        poller: The LROPoller or AsyncLROPoller instance
        poller_type: The type of poller (ANALYZER_CREATION or ANALYZE_CALL) - REQUIRED
        
    Returns:
        str: The operation ID extracted from the poller
        
    Raises:
        ValueError: If no operation ID can be extracted from the poller or if poller_type is not provided
    """
    if poller_type is None:
        raise ValueError("poller_type is required and must be specified (ANALYZER_CREATION or ANALYZE_CALL)")
    # Extract from Operation-Location header (standard approach)
    initial_response = poller.polling_method()._initial_response
    operation_location = initial_response.http_response.headers.get("Operation-Location")
    print("---------------")
    print(f"Operation-Location header: {operation_location}")
    print(f"Poller type: {poller_type}")
    print("---------------")
    
    if operation_location:
        if poller_type == PollerType.ANALYZER_CREATION:
            # Pattern: https://endpoint/.../operations/{operation_id}?api-version=...
            if "/operations/" in operation_location:
                operation_id = operation_location.split("/operations/")[1].split("?")[0]
                return operation_id
        elif poller_type == PollerType.ANALYZE_CALL:
            # Pattern: https://endpoint/.../analyzerResults/{operation_id}?api-version=...
            if "/analyzerResults/" in operation_location:
                operation_id = operation_location.split("/analyzerResults/")[1].split("?")[0]
                return operation_id
    
    raise ValueError(f"Could not extract operation ID from poller for type {poller_type}")


def new_simple_content_analyzer_object(analyzer_id: str, description: Optional[str] = None, tags: Optional[Dict[str, str]] = None) -> ContentAnalyzer:
    """Create a simple ContentAnalyzer object with default configuration.
    
    Args:
        analyzer_id: The analyzer ID
        description: Optional description for the analyzer
        tags: Optional tags for the analyzer
        
    Returns:
        ContentAnalyzer: A configured ContentAnalyzer object
    """
    if description is None:
        description = f"test analyzer: {analyzer_id}"
    if tags is None:
        tags = {"test_type": "simple"}
        
    return ContentAnalyzer(
        base_analyzer_id="prebuilt-documentAnalyzer",
        config=ContentAnalyzerConfig(
            enable_formula=True,
            enable_layout=True,
            enable_ocr=True,
            estimate_field_source_and_confidence=True,
            return_details=True,
        ),
        description=description,
        field_schema=FieldSchema(
            fields={
                "total_amount": FieldDefinition(
                    description="Total amount of this table",
                    method=GenerationMethod.EXTRACT,
                    type=FieldType.NUMBER,
                )
            },
            description="schema description here",
            name="schema name here",
        ),
        mode=AnalysisMode.STANDARD,
        processing_location=ProcessingLocation.GLOBAL,
        tags=tags,
    )


def new_marketing_video_analyzer_object(analyzer_id: str, description: Optional[str] = None, tags: Optional[Dict[str, str]] = None) -> ContentAnalyzer:
    """Create a marketing video ContentAnalyzer object based on the marketing video template.
    
    Args:
        analyzer_id: The analyzer ID
        description: Optional description for the analyzer
        tags: Optional tags for the analyzer
        
    Returns:
        ContentAnalyzer: A configured ContentAnalyzer object for video analysis
    """
    if description is None:
        description = f"marketing video analyzer: {analyzer_id}"
    if tags is None:
        tags = {"test_type": "marketing_video"}
        
    return ContentAnalyzer(
        base_analyzer_id="prebuilt-videoAnalyzer",
        config=ContentAnalyzerConfig(
            return_details=True,
        ),
        description=description,
        mode=AnalysisMode.STANDARD,
        processing_location=ProcessingLocation.GLOBAL,
        tags=tags,
    )


def assert_poller_properties(poller, poller_name: str = "Poller"):
    """Assert common poller properties for any LROPoller or AsyncLROPoller.
    
    Args:
        poller: The LROPoller or AsyncLROPoller instance to validate
        poller_name: Optional name for the poller in log messages
        
    Raises:
        AssertionError: If any poller property assertion fails
    """
    assert poller is not None, f"{poller_name} should not be None"
    assert poller.status() is not None, f"{poller_name} status should not be None"
    assert poller.status() is not "", f"{poller_name} status should not be empty"
    assert poller.continuation_token() is not None, f"{poller_name} continuation_token should not be None"
    print(f"{poller_name} properties verified successfully")


def assert_simple_content_analyzer_result(analysis_result, result_name: str = "Analysis result"):
    """Assert simple content analyzer result properties and field extraction.
    
    Args:
        analysis_result: The analysis result object to validate
        result_name: Optional name for the result in log messages
        
    Raises:
        AssertionError: If any analysis result property assertion fails
    """
    print(f"Validating {result_name} properties")
    assert analysis_result is not None, f"{result_name} should not be None"
    assert analysis_result.__class__.__name__ == "AnalyzeResult", f"{result_name} should be AnalyzeResult, got {analysis_result.__class__.__name__}"
    assert analysis_result.contents is not None, f"{result_name} should have contents"
    assert len(analysis_result.contents) > 0, f"{result_name} should have at least one content"
    
    print(f"{result_name} properties verified successfully")

    # Verify fields node exists in the first result of contents
    
    first_content = analysis_result.contents[0]
    assert hasattr(first_content, 'fields'), "First content should have fields"
    print(f"Verified fields node exists in first result")

    # Verify total_amount field exists and equals 110
    fields = first_content.fields
    
    # Fields is expected to be a dictionary
    assert isinstance(fields, dict), f"Fields should be a dictionary, got {type(fields)}"
    assert 'total_amount' in fields, f"Fields should contain total_amount. Available fields: {list(fields.keys())}"
    
    total_amount_field = fields['total_amount']
    assert total_amount_field is not None, "total_amount field should not be None"
    assert total_amount_field.__class__.__name__ == "NumberField", f"total_amount field should be of type NumberField, got {total_amount_field.__class__.__name__}"

    total_amount_value = total_amount_field.value_number
    
    print(f"Total amount field value: {total_amount_value}")
    assert total_amount_value == 110, f"Expected total_amount to be 110, but got {total_amount_value}"
    print(f"Total amount field validation successful")


def save_analysis_result_to_file(analysis_result, test_name: str, test_pyfile_dir: str, identifier: Optional[str] = None, output_dir: str = "test_output") -> str:
    """Save analysis result to output file using pytest naming convention.
    
    Args:
        analysis_result: The analysis result object to save
        test_name: Name of the test case (e.g., function name)
        test_pyfile_dir: Directory where pytest files are located
        identifier: Optional unique identifier for the result (e.g., analyzer_id)
        output_dir: Directory name to save the output file (default: "test_output")
        
    Returns:
        str: Path to the saved output file
        
    Raises:
        OSError: If there are issues creating directory or writing file
    """
    # Create output directory if it doesn't exist
    output_dir_path = os.path.join(test_pyfile_dir, output_dir)
    os.makedirs(output_dir_path, exist_ok=True)
    
    # Generate output filename with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Build filename with test name and optional identifier
    if identifier:
        output_filename = f"{test_name}_{identifier}_{timestamp}.json"
    else:
        output_filename = f"{test_name}_{timestamp}.json"
    
    saved_file_path = os.path.join(output_dir_path, output_filename)
    
    # Save the analysis result
    with open(saved_file_path, "w") as output_file:
        json.dump(analysis_result.as_dict(), output_file, indent=2)
    
    print(f"Analysis result saved to: {saved_file_path}")
    return saved_file_path


def save_keyframe_image_to_file(
    image_content: bytes, 
    keyframe_id: str, 
    test_name: str, 
    test_pyfile_dir: str, 
    identifier: Optional[str] = None,
    output_dir: str = "test_output"
) -> str:
    """Save keyframe image to output file using pytest naming convention.
    
    Args:
        image_content: The binary image content to save
        keyframe_id: The keyframe ID (e.g., "keyFrame.1")
        test_name: Name of the test case (e.g., function name)
        test_pyfile_dir: Directory where pytest files are located
        identifier: Optional unique identifier to avoid conflicts (e.g., analyzer_id)
        output_dir: Directory name to save the output file (default: "test_output")
        
    Returns:
        str: Path to the saved image file
        
    Raises:
        OSError: If there are issues creating directory or writing file
    """
    # Generate timestamp and frame ID
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    frame_id = keyframe_id.replace('keyFrame.', '')
    
    # Create output directory if it doesn't exist
    output_dir_path = os.path.join(test_pyfile_dir, output_dir)
    os.makedirs(output_dir_path, exist_ok=True)
    
    # Generate output filename with optional identifier to avoid conflicts
    if identifier:
        output_filename = f"{test_name}_{identifier}_{timestamp}_{frame_id}.jpg"
    else:
        output_filename = f"{test_name}_{timestamp}_{frame_id}.jpg"
    
    saved_file_path = os.path.join(output_dir_path, output_filename)
    
    # Write the image content to file
    with open(saved_file_path, "wb") as image_file:
        image_file.write(image_content)
    
    print(f"Image file saved to: {saved_file_path}")
    return saved_file_path 